{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "a = torch.ones(2, 10)\n",
    "b = torch.ones(1, 10)\n",
    "c = torch.ones(4, 10)\n",
    "d = pad_sequence([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "seq = torch.tensor([[1, 2, 0], [3, 0, 0], [4, 5, 6]])\n",
    "lens = [2, 1, 3]\n",
    "packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)\n",
    "packed\n",
    "seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)\n",
    "seq_unpacked\n",
    "lens_unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, lens, packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset # huggingface datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"stas/openwebtext-10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataset[\"train\"].map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "conv1 = nn.Conv2d(3, 4, kernel_size=3, \n",
    "                               stride=4, padding=1, bias=False)\n",
    "conv2 = nn.Conv2d(3, 4, kernel_size=1, \n",
    "                               stride=4, padding=0, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1(torch.randn(1, 3, 10, 10)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2(torch.randn(1, 3, 10, 10)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "logits = torch.tensor([[0.5, 0.5], [0.5, 0.5]])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(logits, torch.tensor([0, -100]), reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "tokenizer_gpt2 = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gpt2.pretrained_vocab_files_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gpt2.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gpt2.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer_gpt2.get_added_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_data = load_dataset('BelleGroup/train_0.5M_CN')\n",
    "\n",
    "def get_training_corpus():\n",
    "    # 为了减少运算时间，只选择较少的训练数据\n",
    "    data = raw_data[\"train\"].select(range(1000))\n",
    "    for idx in range(0, len(data), 1000):\n",
    "        samples = data[idx : idx + 1000]\n",
    "        yield samples.get('instruction', []) + samples.get('output', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_zh = tokenizer_gpt2.train_new_from_iterator(get_training_corpus(), 330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer_zh.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_zh.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe41c06613d4e8b82802ccd614f50a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fb68bb4b0e421482933130335d3544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/18.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5933805b51764a55a32005001f33bb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7620690410884320bb429ebbafa7356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cb52d9b5dd45d29acd2c279e9ba850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/941M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7cd14ced344049b43d6a2a518a43da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8a951a18374ed794d89250e30c61b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10948957c1ef4c369e94879f3666010a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d87f9586634bc4b1ce3383edda0705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc59d1014eb74aed96ddd8529b2ce692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This can take a few minutes to load, so grab a coffee or tea while you wait!\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_datasets[\"train\"].select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def setparents(self):\n",
      "        \"\"\"Correct all parent relations for elements within the scop. There is sually no need to call this directly, invoked implicitly by :meth:`copy`\"\"\"\n",
      "        for c in self:\n",
      "            if isinstance(c, AbstractElement):\n",
      "                c.parent = self\n",
      "                c.setparents()\n"
     ]
    }
   ],
   "source": [
    "print(data[1]['whole_func_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['func_code_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(data['func_code_string']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t',\n",
       " '\\n',\n",
       " '\\r',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\xa0',\n",
       " '°',\n",
       " '±',\n",
       " '²',\n",
       " '³',\n",
       " '·',\n",
       " '¸',\n",
       " 'º',\n",
       " 'É',\n",
       " '×',\n",
       " 'Ø',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'ç',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'í',\n",
       " 'ó',\n",
       " 'õ',\n",
       " 'ö',\n",
       " 'Δ',\n",
       " 'Ω',\n",
       " 'δ',\n",
       " 'ε',\n",
       " 'λ',\n",
       " 'μ',\n",
       " 'π',\n",
       " 'ρ',\n",
       " 'σ',\n",
       " 'τ',\n",
       " 'Б',\n",
       " 'И',\n",
       " 'а',\n",
       " 'б',\n",
       " 'в',\n",
       " 'д',\n",
       " 'ж',\n",
       " 'к',\n",
       " 'н',\n",
       " 'о',\n",
       " 'п',\n",
       " 'р',\n",
       " 'с',\n",
       " 'т',\n",
       " 'у',\n",
       " 'ы',\n",
       " 'я',\n",
       " '‐',\n",
       " '–',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '⁶',\n",
       " '→',\n",
       " '↦',\n",
       " '⇒',\n",
       " '∂',\n",
       " '∈',\n",
       " '−',\n",
       " '∗',\n",
       " '≤',\n",
       " '≥',\n",
       " '⌟',\n",
       " '─',\n",
       " '│',\n",
       " '┌',\n",
       " '┐',\n",
       " '└',\n",
       " '├',\n",
       " '┤',\n",
       " '◆',\n",
       " '☺',\n",
       " '✓',\n",
       " '✖',\n",
       " '、',\n",
       " '。',\n",
       " '一',\n",
       " '上',\n",
       " '下',\n",
       " '不',\n",
       " '与',\n",
       " '专',\n",
       " '两',\n",
       " '个',\n",
       " '中',\n",
       " '串',\n",
       " '为',\n",
       " '之',\n",
       " '乐',\n",
       " '了',\n",
       " '二',\n",
       " '于',\n",
       " '云',\n",
       " '享',\n",
       " '人',\n",
       " '他',\n",
       " '代',\n",
       " '以',\n",
       " '件',\n",
       " '传',\n",
       " '但',\n",
       " '位',\n",
       " '住',\n",
       " '余',\n",
       " '作',\n",
       " '使',\n",
       " '保',\n",
       " '信',\n",
       " '候',\n",
       " '值',\n",
       " '先',\n",
       " '免',\n",
       " '入',\n",
       " '全',\n",
       " '共',\n",
       " '关',\n",
       " '其',\n",
       " '内',\n",
       " '再',\n",
       " '冗',\n",
       " '况',\n",
       " '出',\n",
       " '分',\n",
       " '列',\n",
       " '则',\n",
       " '创',\n",
       " '到',\n",
       " '制',\n",
       " '前',\n",
       " '功',\n",
       " '加',\n",
       " '动',\n",
       " '包',\n",
       " '化',\n",
       " '华',\n",
       " '单',\n",
       " '即',\n",
       " '原',\n",
       " '参',\n",
       " '友',\n",
       " '双',\n",
       " '发',\n",
       " '取',\n",
       " '口',\n",
       " '只',\n",
       " '可',\n",
       " '台',\n",
       " '合',\n",
       " '同',\n",
       " '名',\n",
       " '后',\n",
       " '向',\n",
       " '否',\n",
       " '含',\n",
       " '启',\n",
       " '和',\n",
       " '品',\n",
       " '回',\n",
       " '因',\n",
       " '在',\n",
       " '地',\n",
       " '址',\n",
       " '型',\n",
       " '增',\n",
       " '处',\n",
       " '复',\n",
       " '外',\n",
       " '多',\n",
       " '大',\n",
       " '头',\n",
       " '好',\n",
       " '如',\n",
       " '始',\n",
       " '子',\n",
       " '字',\n",
       " '存',\n",
       " '定',\n",
       " '密',\n",
       " '对',\n",
       " '导',\n",
       " '小',\n",
       " '少',\n",
       " '就',\n",
       " '已',\n",
       " '布',\n",
       " '并',\n",
       " '序',\n",
       " '应',\n",
       " '建',\n",
       " '开',\n",
       " '式',\n",
       " '弹',\n",
       " '当',\n",
       " '录',\n",
       " '很',\n",
       " '得',\n",
       " '必',\n",
       " '忽',\n",
       " '态',\n",
       " '性',\n",
       " '总',\n",
       " '息',\n",
       " '您',\n",
       " '情',\n",
       " '慎',\n",
       " '成',\n",
       " '或',\n",
       " '户',\n",
       " '所',\n",
       " '手',\n",
       " '才',\n",
       " '打',\n",
       " '找',\n",
       " '括',\n",
       " '持',\n",
       " '据',\n",
       " '排',\n",
       " '接',\n",
       " '插',\n",
       " '搜',\n",
       " '播',\n",
       " '操',\n",
       " '支',\n",
       " '收',\n",
       " '放',\n",
       " '效',\n",
       " '数',\n",
       " '整',\n",
       " '文',\n",
       " '新',\n",
       " '方',\n",
       " '无',\n",
       " '时',\n",
       " '易',\n",
       " '是',\n",
       " '显',\n",
       " '曲',\n",
       " '更',\n",
       " '最',\n",
       " '有',\n",
       " '未',\n",
       " '末',\n",
       " '本',\n",
       " '机',\n",
       " '权',\n",
       " '来',\n",
       " '板',\n",
       " '果',\n",
       " '染',\n",
       " '查',\n",
       " '样',\n",
       " '根',\n",
       " '格',\n",
       " '档',\n",
       " '模',\n",
       " '次',\n",
       " '欧',\n",
       " '歌',\n",
       " '此',\n",
       " '段',\n",
       " '比',\n",
       " '没',\n",
       " '法',\n",
       " '注',\n",
       " '渲',\n",
       " '滤',\n",
       " '然',\n",
       " '父',\n",
       " '独',\n",
       " '理',\n",
       " '生',\n",
       " '用',\n",
       " '由',\n",
       " '申',\n",
       " '电',\n",
       " '留',\n",
       " '略',\n",
       " '登',\n",
       " '的',\n",
       " '相',\n",
       " '看',\n",
       " '码',\n",
       " '确',\n",
       " '示',\n",
       " '站',\n",
       " '章',\n",
       " '符',\n",
       " '第',\n",
       " '等',\n",
       " '签',\n",
       " '简',\n",
       " '箱',\n",
       " '类',\n",
       " '精',\n",
       " '索',\n",
       " '级',\n",
       " '组',\n",
       " '细',\n",
       " '结',\n",
       " '给',\n",
       " '编',\n",
       " '网',\n",
       " '置',\n",
       " '美',\n",
       " '考',\n",
       " '者',\n",
       " '联',\n",
       " '能',\n",
       " '航',\n",
       " '节',\n",
       " '获',\n",
       " '菜',\n",
       " '落',\n",
       " '藏',\n",
       " '虑',\n",
       " '行',\n",
       " '表',\n",
       " '要',\n",
       " '视',\n",
       " '订',\n",
       " '认',\n",
       " '记',\n",
       " '论',\n",
       " '访',\n",
       " '证',\n",
       " '评',\n",
       " '词',\n",
       " '询',\n",
       " '该',\n",
       " '详',\n",
       " '语',\n",
       " '请',\n",
       " '调',\n",
       " '谨',\n",
       " '象',\n",
       " '起',\n",
       " '超',\n",
       " '载',\n",
       " '辑',\n",
       " '过',\n",
       " '近',\n",
       " '返',\n",
       " '这',\n",
       " '进',\n",
       " '选',\n",
       " '通',\n",
       " '避',\n",
       " '邮',\n",
       " '部',\n",
       " '里',\n",
       " '重',\n",
       " '量',\n",
       " '针',\n",
       " '钟',\n",
       " '链',\n",
       " '错',\n",
       " '键',\n",
       " '长',\n",
       " '问',\n",
       " '间',\n",
       " '陆',\n",
       " '限',\n",
       " '随',\n",
       " '需',\n",
       " '面',\n",
       " '音',\n",
       " '页',\n",
       " '项',\n",
       " '须',\n",
       " '频',\n",
       " '题',\n",
       " '首',\n",
       " '验',\n",
       " '默',\n",
       " '！',\n",
       " '（',\n",
       " '）',\n",
       " '，',\n",
       " '：',\n",
       " '；',\n",
       " '？']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2ind = {s : i + 1 for i, s in enumerate(chars)}\n",
    "char2ind['<|endoftext|>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 1,\n",
       " '\\n': 2,\n",
       " '\\r': 3,\n",
       " ' ': 4,\n",
       " '!': 5,\n",
       " '\"': 6,\n",
       " '#': 7,\n",
       " '$': 8,\n",
       " '%': 9,\n",
       " '&': 10,\n",
       " \"'\": 11,\n",
       " '(': 12,\n",
       " ')': 13,\n",
       " '*': 14,\n",
       " '+': 15,\n",
       " ',': 16,\n",
       " '-': 17,\n",
       " '.': 18,\n",
       " '/': 19,\n",
       " '0': 20,\n",
       " '1': 21,\n",
       " '2': 22,\n",
       " '3': 23,\n",
       " '4': 24,\n",
       " '5': 25,\n",
       " '6': 26,\n",
       " '7': 27,\n",
       " '8': 28,\n",
       " '9': 29,\n",
       " ':': 30,\n",
       " ';': 31,\n",
       " '<': 32,\n",
       " '=': 33,\n",
       " '>': 34,\n",
       " '?': 35,\n",
       " '@': 36,\n",
       " 'A': 37,\n",
       " 'B': 38,\n",
       " 'C': 39,\n",
       " 'D': 40,\n",
       " 'E': 41,\n",
       " 'F': 42,\n",
       " 'G': 43,\n",
       " 'H': 44,\n",
       " 'I': 45,\n",
       " 'J': 46,\n",
       " 'K': 47,\n",
       " 'L': 48,\n",
       " 'M': 49,\n",
       " 'N': 50,\n",
       " 'O': 51,\n",
       " 'P': 52,\n",
       " 'Q': 53,\n",
       " 'R': 54,\n",
       " 'S': 55,\n",
       " 'T': 56,\n",
       " 'U': 57,\n",
       " 'V': 58,\n",
       " 'W': 59,\n",
       " 'X': 60,\n",
       " 'Y': 61,\n",
       " 'Z': 62,\n",
       " '[': 63,\n",
       " '\\\\': 64,\n",
       " ']': 65,\n",
       " '^': 66,\n",
       " '_': 67,\n",
       " '`': 68,\n",
       " 'a': 69,\n",
       " 'b': 70,\n",
       " 'c': 71,\n",
       " 'd': 72,\n",
       " 'e': 73,\n",
       " 'f': 74,\n",
       " 'g': 75,\n",
       " 'h': 76,\n",
       " 'i': 77,\n",
       " 'j': 78,\n",
       " 'k': 79,\n",
       " 'l': 80,\n",
       " 'm': 81,\n",
       " 'n': 82,\n",
       " 'o': 83,\n",
       " 'p': 84,\n",
       " 'q': 85,\n",
       " 'r': 86,\n",
       " 's': 87,\n",
       " 't': 88,\n",
       " 'u': 89,\n",
       " 'v': 90,\n",
       " 'w': 91,\n",
       " 'x': 92,\n",
       " 'y': 93,\n",
       " 'z': 94,\n",
       " '{': 95,\n",
       " '|': 96,\n",
       " '}': 97,\n",
       " '~': 98,\n",
       " '\\xa0': 99,\n",
       " '°': 100,\n",
       " '±': 101,\n",
       " '²': 102,\n",
       " '³': 103,\n",
       " '·': 104,\n",
       " '¸': 105,\n",
       " 'º': 106,\n",
       " 'É': 107,\n",
       " '×': 108,\n",
       " 'Ø': 109,\n",
       " 'á': 110,\n",
       " 'â': 111,\n",
       " 'ã': 112,\n",
       " 'ä': 113,\n",
       " 'ç': 114,\n",
       " 'é': 115,\n",
       " 'ê': 116,\n",
       " 'í': 117,\n",
       " 'ó': 118,\n",
       " 'õ': 119,\n",
       " 'ö': 120,\n",
       " 'Δ': 121,\n",
       " 'Ω': 122,\n",
       " 'δ': 123,\n",
       " 'ε': 124,\n",
       " 'λ': 125,\n",
       " 'μ': 126,\n",
       " 'π': 127,\n",
       " 'ρ': 128,\n",
       " 'σ': 129,\n",
       " 'τ': 130,\n",
       " 'Б': 131,\n",
       " 'И': 132,\n",
       " 'а': 133,\n",
       " 'б': 134,\n",
       " 'в': 135,\n",
       " 'д': 136,\n",
       " 'ж': 137,\n",
       " 'к': 138,\n",
       " 'н': 139,\n",
       " 'о': 140,\n",
       " 'п': 141,\n",
       " 'р': 142,\n",
       " 'с': 143,\n",
       " 'т': 144,\n",
       " 'у': 145,\n",
       " 'ы': 146,\n",
       " 'я': 147,\n",
       " '‐': 148,\n",
       " '–': 149,\n",
       " '‘': 150,\n",
       " '’': 151,\n",
       " '“': 152,\n",
       " '”': 153,\n",
       " '⁶': 154,\n",
       " '→': 155,\n",
       " '↦': 156,\n",
       " '⇒': 157,\n",
       " '∂': 158,\n",
       " '∈': 159,\n",
       " '−': 160,\n",
       " '∗': 161,\n",
       " '≤': 162,\n",
       " '≥': 163,\n",
       " '⌟': 164,\n",
       " '─': 165,\n",
       " '│': 166,\n",
       " '┌': 167,\n",
       " '┐': 168,\n",
       " '└': 169,\n",
       " '├': 170,\n",
       " '┤': 171,\n",
       " '◆': 172,\n",
       " '☺': 173,\n",
       " '✓': 174,\n",
       " '✖': 175,\n",
       " '、': 176,\n",
       " '。': 177,\n",
       " '一': 178,\n",
       " '上': 179,\n",
       " '下': 180,\n",
       " '不': 181,\n",
       " '与': 182,\n",
       " '专': 183,\n",
       " '两': 184,\n",
       " '个': 185,\n",
       " '中': 186,\n",
       " '串': 187,\n",
       " '为': 188,\n",
       " '之': 189,\n",
       " '乐': 190,\n",
       " '了': 191,\n",
       " '二': 192,\n",
       " '于': 193,\n",
       " '云': 194,\n",
       " '享': 195,\n",
       " '人': 196,\n",
       " '他': 197,\n",
       " '代': 198,\n",
       " '以': 199,\n",
       " '件': 200,\n",
       " '传': 201,\n",
       " '但': 202,\n",
       " '位': 203,\n",
       " '住': 204,\n",
       " '余': 205,\n",
       " '作': 206,\n",
       " '使': 207,\n",
       " '保': 208,\n",
       " '信': 209,\n",
       " '候': 210,\n",
       " '值': 211,\n",
       " '先': 212,\n",
       " '免': 213,\n",
       " '入': 214,\n",
       " '全': 215,\n",
       " '共': 216,\n",
       " '关': 217,\n",
       " '其': 218,\n",
       " '内': 219,\n",
       " '再': 220,\n",
       " '冗': 221,\n",
       " '况': 222,\n",
       " '出': 223,\n",
       " '分': 224,\n",
       " '列': 225,\n",
       " '则': 226,\n",
       " '创': 227,\n",
       " '到': 228,\n",
       " '制': 229,\n",
       " '前': 230,\n",
       " '功': 231,\n",
       " '加': 232,\n",
       " '动': 233,\n",
       " '包': 234,\n",
       " '化': 235,\n",
       " '华': 236,\n",
       " '单': 237,\n",
       " '即': 238,\n",
       " '原': 239,\n",
       " '参': 240,\n",
       " '友': 241,\n",
       " '双': 242,\n",
       " '发': 243,\n",
       " '取': 244,\n",
       " '口': 245,\n",
       " '只': 246,\n",
       " '可': 247,\n",
       " '台': 248,\n",
       " '合': 249,\n",
       " '同': 250,\n",
       " '名': 251,\n",
       " '后': 252,\n",
       " '向': 253,\n",
       " '否': 254,\n",
       " '含': 255,\n",
       " '启': 256,\n",
       " '和': 257,\n",
       " '品': 258,\n",
       " '回': 259,\n",
       " '因': 260,\n",
       " '在': 261,\n",
       " '地': 262,\n",
       " '址': 263,\n",
       " '型': 264,\n",
       " '增': 265,\n",
       " '处': 266,\n",
       " '复': 267,\n",
       " '外': 268,\n",
       " '多': 269,\n",
       " '大': 270,\n",
       " '头': 271,\n",
       " '好': 272,\n",
       " '如': 273,\n",
       " '始': 274,\n",
       " '子': 275,\n",
       " '字': 276,\n",
       " '存': 277,\n",
       " '定': 278,\n",
       " '密': 279,\n",
       " '对': 280,\n",
       " '导': 281,\n",
       " '小': 282,\n",
       " '少': 283,\n",
       " '就': 284,\n",
       " '已': 285,\n",
       " '布': 286,\n",
       " '并': 287,\n",
       " '序': 288,\n",
       " '应': 289,\n",
       " '建': 290,\n",
       " '开': 291,\n",
       " '式': 292,\n",
       " '弹': 293,\n",
       " '当': 294,\n",
       " '录': 295,\n",
       " '很': 296,\n",
       " '得': 297,\n",
       " '必': 298,\n",
       " '忽': 299,\n",
       " '态': 300,\n",
       " '性': 301,\n",
       " '总': 302,\n",
       " '息': 303,\n",
       " '您': 304,\n",
       " '情': 305,\n",
       " '慎': 306,\n",
       " '成': 307,\n",
       " '或': 308,\n",
       " '户': 309,\n",
       " '所': 310,\n",
       " '手': 311,\n",
       " '才': 312,\n",
       " '打': 313,\n",
       " '找': 314,\n",
       " '括': 315,\n",
       " '持': 316,\n",
       " '据': 317,\n",
       " '排': 318,\n",
       " '接': 319,\n",
       " '插': 320,\n",
       " '搜': 321,\n",
       " '播': 322,\n",
       " '操': 323,\n",
       " '支': 324,\n",
       " '收': 325,\n",
       " '放': 326,\n",
       " '效': 327,\n",
       " '数': 328,\n",
       " '整': 329,\n",
       " '文': 330,\n",
       " '新': 331,\n",
       " '方': 332,\n",
       " '无': 333,\n",
       " '时': 334,\n",
       " '易': 335,\n",
       " '是': 336,\n",
       " '显': 337,\n",
       " '曲': 338,\n",
       " '更': 339,\n",
       " '最': 340,\n",
       " '有': 341,\n",
       " '未': 342,\n",
       " '末': 343,\n",
       " '本': 344,\n",
       " '机': 345,\n",
       " '权': 346,\n",
       " '来': 347,\n",
       " '板': 348,\n",
       " '果': 349,\n",
       " '染': 350,\n",
       " '查': 351,\n",
       " '样': 352,\n",
       " '根': 353,\n",
       " '格': 354,\n",
       " '档': 355,\n",
       " '模': 356,\n",
       " '次': 357,\n",
       " '欧': 358,\n",
       " '歌': 359,\n",
       " '此': 360,\n",
       " '段': 361,\n",
       " '比': 362,\n",
       " '没': 363,\n",
       " '法': 364,\n",
       " '注': 365,\n",
       " '渲': 366,\n",
       " '滤': 367,\n",
       " '然': 368,\n",
       " '父': 369,\n",
       " '独': 370,\n",
       " '理': 371,\n",
       " '生': 372,\n",
       " '用': 373,\n",
       " '由': 374,\n",
       " '申': 375,\n",
       " '电': 376,\n",
       " '留': 377,\n",
       " '略': 378,\n",
       " '登': 379,\n",
       " '的': 380,\n",
       " '相': 381,\n",
       " '看': 382,\n",
       " '码': 383,\n",
       " '确': 384,\n",
       " '示': 385,\n",
       " '站': 386,\n",
       " '章': 387,\n",
       " '符': 388,\n",
       " '第': 389,\n",
       " '等': 390,\n",
       " '签': 391,\n",
       " '简': 392,\n",
       " '箱': 393,\n",
       " '类': 394,\n",
       " '精': 395,\n",
       " '索': 396,\n",
       " '级': 397,\n",
       " '组': 398,\n",
       " '细': 399,\n",
       " '结': 400,\n",
       " '给': 401,\n",
       " '编': 402,\n",
       " '网': 403,\n",
       " '置': 404,\n",
       " '美': 405,\n",
       " '考': 406,\n",
       " '者': 407,\n",
       " '联': 408,\n",
       " '能': 409,\n",
       " '航': 410,\n",
       " '节': 411,\n",
       " '获': 412,\n",
       " '菜': 413,\n",
       " '落': 414,\n",
       " '藏': 415,\n",
       " '虑': 416,\n",
       " '行': 417,\n",
       " '表': 418,\n",
       " '要': 419,\n",
       " '视': 420,\n",
       " '订': 421,\n",
       " '认': 422,\n",
       " '记': 423,\n",
       " '论': 424,\n",
       " '访': 425,\n",
       " '证': 426,\n",
       " '评': 427,\n",
       " '词': 428,\n",
       " '询': 429,\n",
       " '该': 430,\n",
       " '详': 431,\n",
       " '语': 432,\n",
       " '请': 433,\n",
       " '调': 434,\n",
       " '谨': 435,\n",
       " '象': 436,\n",
       " '起': 437,\n",
       " '超': 438,\n",
       " '载': 439,\n",
       " '辑': 440,\n",
       " '过': 441,\n",
       " '近': 442,\n",
       " '返': 443,\n",
       " '这': 444,\n",
       " '进': 445,\n",
       " '选': 446,\n",
       " '通': 447,\n",
       " '避': 448,\n",
       " '邮': 449,\n",
       " '部': 450,\n",
       " '里': 451,\n",
       " '重': 452,\n",
       " '量': 453,\n",
       " '针': 454,\n",
       " '钟': 455,\n",
       " '链': 456,\n",
       " '错': 457,\n",
       " '键': 458,\n",
       " '长': 459,\n",
       " '问': 460,\n",
       " '间': 461,\n",
       " '陆': 462,\n",
       " '限': 463,\n",
       " '随': 464,\n",
       " '需': 465,\n",
       " '面': 466,\n",
       " '音': 467,\n",
       " '页': 468,\n",
       " '项': 469,\n",
       " '须': 470,\n",
       " '频': 471,\n",
       " '题': 472,\n",
       " '首': 473,\n",
       " '验': 474,\n",
       " '默': 475,\n",
       " '！': 476,\n",
       " '（': 477,\n",
       " '）': 478,\n",
       " '，': 479,\n",
       " '：': 480,\n",
       " '；': 481,\n",
       " '？': 482,\n",
       " '<|endoftext|>': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '\\t',\n",
       " 2: '\\n',\n",
       " 3: '\\r',\n",
       " 4: ' ',\n",
       " 5: '!',\n",
       " 6: '\"',\n",
       " 7: '#',\n",
       " 8: '$',\n",
       " 9: '%',\n",
       " 10: '&',\n",
       " 11: \"'\",\n",
       " 12: '(',\n",
       " 13: ')',\n",
       " 14: '*',\n",
       " 15: '+',\n",
       " 16: ',',\n",
       " 17: '-',\n",
       " 18: '.',\n",
       " 19: '/',\n",
       " 20: '0',\n",
       " 21: '1',\n",
       " 22: '2',\n",
       " 23: '3',\n",
       " 24: '4',\n",
       " 25: '5',\n",
       " 26: '6',\n",
       " 27: '7',\n",
       " 28: '8',\n",
       " 29: '9',\n",
       " 30: ':',\n",
       " 31: ';',\n",
       " 32: '<',\n",
       " 33: '=',\n",
       " 34: '>',\n",
       " 35: '?',\n",
       " 36: '@',\n",
       " 37: 'A',\n",
       " 38: 'B',\n",
       " 39: 'C',\n",
       " 40: 'D',\n",
       " 41: 'E',\n",
       " 42: 'F',\n",
       " 43: 'G',\n",
       " 44: 'H',\n",
       " 45: 'I',\n",
       " 46: 'J',\n",
       " 47: 'K',\n",
       " 48: 'L',\n",
       " 49: 'M',\n",
       " 50: 'N',\n",
       " 51: 'O',\n",
       " 52: 'P',\n",
       " 53: 'Q',\n",
       " 54: 'R',\n",
       " 55: 'S',\n",
       " 56: 'T',\n",
       " 57: 'U',\n",
       " 58: 'V',\n",
       " 59: 'W',\n",
       " 60: 'X',\n",
       " 61: 'Y',\n",
       " 62: 'Z',\n",
       " 63: '[',\n",
       " 64: '\\\\',\n",
       " 65: ']',\n",
       " 66: '^',\n",
       " 67: '_',\n",
       " 68: '`',\n",
       " 69: 'a',\n",
       " 70: 'b',\n",
       " 71: 'c',\n",
       " 72: 'd',\n",
       " 73: 'e',\n",
       " 74: 'f',\n",
       " 75: 'g',\n",
       " 76: 'h',\n",
       " 77: 'i',\n",
       " 78: 'j',\n",
       " 79: 'k',\n",
       " 80: 'l',\n",
       " 81: 'm',\n",
       " 82: 'n',\n",
       " 83: 'o',\n",
       " 84: 'p',\n",
       " 85: 'q',\n",
       " 86: 'r',\n",
       " 87: 's',\n",
       " 88: 't',\n",
       " 89: 'u',\n",
       " 90: 'v',\n",
       " 91: 'w',\n",
       " 92: 'x',\n",
       " 93: 'y',\n",
       " 94: 'z',\n",
       " 95: '{',\n",
       " 96: '|',\n",
       " 97: '}',\n",
       " 98: '~',\n",
       " 99: '\\xa0',\n",
       " 100: '°',\n",
       " 101: '±',\n",
       " 102: '²',\n",
       " 103: '³',\n",
       " 104: '·',\n",
       " 105: '¸',\n",
       " 106: 'º',\n",
       " 107: 'É',\n",
       " 108: '×',\n",
       " 109: 'Ø',\n",
       " 110: 'á',\n",
       " 111: 'â',\n",
       " 112: 'ã',\n",
       " 113: 'ä',\n",
       " 114: 'ç',\n",
       " 115: 'é',\n",
       " 116: 'ê',\n",
       " 117: 'í',\n",
       " 118: 'ó',\n",
       " 119: 'õ',\n",
       " 120: 'ö',\n",
       " 121: 'Δ',\n",
       " 122: 'Ω',\n",
       " 123: 'δ',\n",
       " 124: 'ε',\n",
       " 125: 'λ',\n",
       " 126: 'μ',\n",
       " 127: 'π',\n",
       " 128: 'ρ',\n",
       " 129: 'σ',\n",
       " 130: 'τ',\n",
       " 131: 'Б',\n",
       " 132: 'И',\n",
       " 133: 'а',\n",
       " 134: 'б',\n",
       " 135: 'в',\n",
       " 136: 'д',\n",
       " 137: 'ж',\n",
       " 138: 'к',\n",
       " 139: 'н',\n",
       " 140: 'о',\n",
       " 141: 'п',\n",
       " 142: 'р',\n",
       " 143: 'с',\n",
       " 144: 'т',\n",
       " 145: 'у',\n",
       " 146: 'ы',\n",
       " 147: 'я',\n",
       " 148: '‐',\n",
       " 149: '–',\n",
       " 150: '‘',\n",
       " 151: '’',\n",
       " 152: '“',\n",
       " 153: '”',\n",
       " 154: '⁶',\n",
       " 155: '→',\n",
       " 156: '↦',\n",
       " 157: '⇒',\n",
       " 158: '∂',\n",
       " 159: '∈',\n",
       " 160: '−',\n",
       " 161: '∗',\n",
       " 162: '≤',\n",
       " 163: '≥',\n",
       " 164: '⌟',\n",
       " 165: '─',\n",
       " 166: '│',\n",
       " 167: '┌',\n",
       " 168: '┐',\n",
       " 169: '└',\n",
       " 170: '├',\n",
       " 171: '┤',\n",
       " 172: '◆',\n",
       " 173: '☺',\n",
       " 174: '✓',\n",
       " 175: '✖',\n",
       " 176: '、',\n",
       " 177: '。',\n",
       " 178: '一',\n",
       " 179: '上',\n",
       " 180: '下',\n",
       " 181: '不',\n",
       " 182: '与',\n",
       " 183: '专',\n",
       " 184: '两',\n",
       " 185: '个',\n",
       " 186: '中',\n",
       " 187: '串',\n",
       " 188: '为',\n",
       " 189: '之',\n",
       " 190: '乐',\n",
       " 191: '了',\n",
       " 192: '二',\n",
       " 193: '于',\n",
       " 194: '云',\n",
       " 195: '享',\n",
       " 196: '人',\n",
       " 197: '他',\n",
       " 198: '代',\n",
       " 199: '以',\n",
       " 200: '件',\n",
       " 201: '传',\n",
       " 202: '但',\n",
       " 203: '位',\n",
       " 204: '住',\n",
       " 205: '余',\n",
       " 206: '作',\n",
       " 207: '使',\n",
       " 208: '保',\n",
       " 209: '信',\n",
       " 210: '候',\n",
       " 211: '值',\n",
       " 212: '先',\n",
       " 213: '免',\n",
       " 214: '入',\n",
       " 215: '全',\n",
       " 216: '共',\n",
       " 217: '关',\n",
       " 218: '其',\n",
       " 219: '内',\n",
       " 220: '再',\n",
       " 221: '冗',\n",
       " 222: '况',\n",
       " 223: '出',\n",
       " 224: '分',\n",
       " 225: '列',\n",
       " 226: '则',\n",
       " 227: '创',\n",
       " 228: '到',\n",
       " 229: '制',\n",
       " 230: '前',\n",
       " 231: '功',\n",
       " 232: '加',\n",
       " 233: '动',\n",
       " 234: '包',\n",
       " 235: '化',\n",
       " 236: '华',\n",
       " 237: '单',\n",
       " 238: '即',\n",
       " 239: '原',\n",
       " 240: '参',\n",
       " 241: '友',\n",
       " 242: '双',\n",
       " 243: '发',\n",
       " 244: '取',\n",
       " 245: '口',\n",
       " 246: '只',\n",
       " 247: '可',\n",
       " 248: '台',\n",
       " 249: '合',\n",
       " 250: '同',\n",
       " 251: '名',\n",
       " 252: '后',\n",
       " 253: '向',\n",
       " 254: '否',\n",
       " 255: '含',\n",
       " 256: '启',\n",
       " 257: '和',\n",
       " 258: '品',\n",
       " 259: '回',\n",
       " 260: '因',\n",
       " 261: '在',\n",
       " 262: '地',\n",
       " 263: '址',\n",
       " 264: '型',\n",
       " 265: '增',\n",
       " 266: '处',\n",
       " 267: '复',\n",
       " 268: '外',\n",
       " 269: '多',\n",
       " 270: '大',\n",
       " 271: '头',\n",
       " 272: '好',\n",
       " 273: '如',\n",
       " 274: '始',\n",
       " 275: '子',\n",
       " 276: '字',\n",
       " 277: '存',\n",
       " 278: '定',\n",
       " 279: '密',\n",
       " 280: '对',\n",
       " 281: '导',\n",
       " 282: '小',\n",
       " 283: '少',\n",
       " 284: '就',\n",
       " 285: '已',\n",
       " 286: '布',\n",
       " 287: '并',\n",
       " 288: '序',\n",
       " 289: '应',\n",
       " 290: '建',\n",
       " 291: '开',\n",
       " 292: '式',\n",
       " 293: '弹',\n",
       " 294: '当',\n",
       " 295: '录',\n",
       " 296: '很',\n",
       " 297: '得',\n",
       " 298: '必',\n",
       " 299: '忽',\n",
       " 300: '态',\n",
       " 301: '性',\n",
       " 302: '总',\n",
       " 303: '息',\n",
       " 304: '您',\n",
       " 305: '情',\n",
       " 306: '慎',\n",
       " 307: '成',\n",
       " 308: '或',\n",
       " 309: '户',\n",
       " 310: '所',\n",
       " 311: '手',\n",
       " 312: '才',\n",
       " 313: '打',\n",
       " 314: '找',\n",
       " 315: '括',\n",
       " 316: '持',\n",
       " 317: '据',\n",
       " 318: '排',\n",
       " 319: '接',\n",
       " 320: '插',\n",
       " 321: '搜',\n",
       " 322: '播',\n",
       " 323: '操',\n",
       " 324: '支',\n",
       " 325: '收',\n",
       " 326: '放',\n",
       " 327: '效',\n",
       " 328: '数',\n",
       " 329: '整',\n",
       " 330: '文',\n",
       " 331: '新',\n",
       " 332: '方',\n",
       " 333: '无',\n",
       " 334: '时',\n",
       " 335: '易',\n",
       " 336: '是',\n",
       " 337: '显',\n",
       " 338: '曲',\n",
       " 339: '更',\n",
       " 340: '最',\n",
       " 341: '有',\n",
       " 342: '未',\n",
       " 343: '末',\n",
       " 344: '本',\n",
       " 345: '机',\n",
       " 346: '权',\n",
       " 347: '来',\n",
       " 348: '板',\n",
       " 349: '果',\n",
       " 350: '染',\n",
       " 351: '查',\n",
       " 352: '样',\n",
       " 353: '根',\n",
       " 354: '格',\n",
       " 355: '档',\n",
       " 356: '模',\n",
       " 357: '次',\n",
       " 358: '欧',\n",
       " 359: '歌',\n",
       " 360: '此',\n",
       " 361: '段',\n",
       " 362: '比',\n",
       " 363: '没',\n",
       " 364: '法',\n",
       " 365: '注',\n",
       " 366: '渲',\n",
       " 367: '滤',\n",
       " 368: '然',\n",
       " 369: '父',\n",
       " 370: '独',\n",
       " 371: '理',\n",
       " 372: '生',\n",
       " 373: '用',\n",
       " 374: '由',\n",
       " 375: '申',\n",
       " 376: '电',\n",
       " 377: '留',\n",
       " 378: '略',\n",
       " 379: '登',\n",
       " 380: '的',\n",
       " 381: '相',\n",
       " 382: '看',\n",
       " 383: '码',\n",
       " 384: '确',\n",
       " 385: '示',\n",
       " 386: '站',\n",
       " 387: '章',\n",
       " 388: '符',\n",
       " 389: '第',\n",
       " 390: '等',\n",
       " 391: '签',\n",
       " 392: '简',\n",
       " 393: '箱',\n",
       " 394: '类',\n",
       " 395: '精',\n",
       " 396: '索',\n",
       " 397: '级',\n",
       " 398: '组',\n",
       " 399: '细',\n",
       " 400: '结',\n",
       " 401: '给',\n",
       " 402: '编',\n",
       " 403: '网',\n",
       " 404: '置',\n",
       " 405: '美',\n",
       " 406: '考',\n",
       " 407: '者',\n",
       " 408: '联',\n",
       " 409: '能',\n",
       " 410: '航',\n",
       " 411: '节',\n",
       " 412: '获',\n",
       " 413: '菜',\n",
       " 414: '落',\n",
       " 415: '藏',\n",
       " 416: '虑',\n",
       " 417: '行',\n",
       " 418: '表',\n",
       " 419: '要',\n",
       " 420: '视',\n",
       " 421: '订',\n",
       " 422: '认',\n",
       " 423: '记',\n",
       " 424: '论',\n",
       " 425: '访',\n",
       " 426: '证',\n",
       " 427: '评',\n",
       " 428: '词',\n",
       " 429: '询',\n",
       " 430: '该',\n",
       " 431: '详',\n",
       " 432: '语',\n",
       " 433: '请',\n",
       " 434: '调',\n",
       " 435: '谨',\n",
       " 436: '象',\n",
       " 437: '起',\n",
       " 438: '超',\n",
       " 439: '载',\n",
       " 440: '辑',\n",
       " 441: '过',\n",
       " 442: '近',\n",
       " 443: '返',\n",
       " 444: '这',\n",
       " 445: '进',\n",
       " 446: '选',\n",
       " 447: '通',\n",
       " 448: '避',\n",
       " 449: '邮',\n",
       " 450: '部',\n",
       " 451: '里',\n",
       " 452: '重',\n",
       " 453: '量',\n",
       " 454: '针',\n",
       " 455: '钟',\n",
       " 456: '链',\n",
       " 457: '错',\n",
       " 458: '键',\n",
       " 459: '长',\n",
       " 460: '问',\n",
       " 461: '间',\n",
       " 462: '陆',\n",
       " 463: '限',\n",
       " 464: '随',\n",
       " 465: '需',\n",
       " 466: '面',\n",
       " 467: '音',\n",
       " 468: '页',\n",
       " 469: '项',\n",
       " 470: '须',\n",
       " 471: '频',\n",
       " 472: '题',\n",
       " 473: '首',\n",
       " 474: '验',\n",
       " 475: '默',\n",
       " 476: '！',\n",
       " 477: '（',\n",
       " 478: '）',\n",
       " 479: '，',\n",
       " 480: '：',\n",
       " 481: '；',\n",
       " 482: '？',\n",
       " 0: '<|endoftext|>'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2char = {i : s for s, i in char2ind.items()}\n",
    "ind2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "\n",
    "def build_dataset(words):  \n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "embedding = torch.randn(10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0708,  0.3567, -0.3461, -0.3142],\n",
       "        [-1.4380, -0.2864, -1.0363,  0.4179],\n",
       "        [-0.3336, -0.1104, -0.3592,  1.9704],\n",
       "        [ 0.3901,  0.2693,  0.4197,  1.0691],\n",
       "        [-2.5862, -0.9876,  2.0897, -0.7323],\n",
       "        [-0.6693,  1.3959,  1.3124, -0.7408],\n",
       "        [ 0.8491,  0.1856, -0.7332, -0.0313],\n",
       "        [ 0.9752,  0.0266,  0.9608, -1.0253],\n",
       "        [-0.1048, -1.6725, -0.1999, -0.2459],\n",
       "        [-0.3935, -0.9368,  0.4273,  0.7951]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4380, -0.2864, -1.0363,  0.4179],\n",
       "        [ 0.3901,  0.2693,  0.4197,  1.0691],\n",
       "        [-2.5862, -0.9876,  2.0897, -0.7323]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[torch.tensor([1, 3, 4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "x = F.one_hot(torch.tensor([1]), num_classes=10).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4380, -0.2864, -1.0363,  0.4179]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9db082dfd83449191547d02337bf247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_dict({\"a\": [0, 1, 2]})\n",
    "dataset_with_duplicates = dataset.map(lambda batch: {\"b\": batch[\"a\"] * 2}, remove_columns=[\"a\"], batched=True)\n",
    "len(dataset_with_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['a'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['b'],\n",
       "    num_rows: 6\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f174b29c05344142a4481581578a76e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 2, 3], [5, 7, 8]]]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "d = Dataset.from_dict({\"foo\": [[[1, 2, 3], [5, 7, 8]]], 'y': [[8, 9]]})\n",
    "b = d.map(lambda x: {'t': [i for row in x[\"foo\"] for i in row], 'yy':  [i for row in x[\"y\"] for i in row]}, batched=True, remove_columns=['foo', 'y'])\n",
    "#nb = d.map(lambda x: {\"foo\": [i for row in x[\"foo\"] for i in row]})\n",
    "\n",
    "\n",
    "print(d[\"foo\"])\n",
    "# [1, 2, 3, 5, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3], [5, 7, 8]], [8, 9])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['t'], b['yy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['t', 'yy'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['foo', 'y'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return [i for row in x for i in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [5, 7, 8]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([[[1, 2, 3], [5, 7, 8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "l = nn.Linear(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=20, bias=True)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(10, 20)\n",
    "input = torch.randn(5, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6609,  0.0288,  0.4044, -0.0861,  0.1431, -0.8551,  0.3041, -0.5963,\n",
       "         -0.2678, -0.7192, -0.3108, -0.4540,  0.0777,  0.3821,  0.4365,  0.1742,\n",
       "         -0.0074, -0.5784, -0.6424, -0.0823],\n",
       "        [ 0.6820,  0.0065,  0.8082, -0.0289,  0.5228, -0.7669, -0.4600,  0.2061,\n",
       "         -0.3060,  0.2323, -0.3815,  0.1412, -0.3332,  0.4825, -0.5178, -0.1881,\n",
       "         -0.1866, -0.4605, -0.6267,  0.0444],\n",
       "        [ 0.3235,  0.3109,  0.2414, -0.1143, -0.6785,  0.3351,  0.7283, -0.7975,\n",
       "         -0.5947, -0.5497,  0.3621, -0.2100,  0.1001, -0.7177,  0.2893,  0.4918,\n",
       "         -0.3884, -0.2158, -0.3640,  0.1690]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn == output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")\n",
    "datasets = raw_datasets[\"train\"].select(range(1000))\n",
    "# 通过索引提取datasets数据的时候，返回一个dict，其中的value是一个字符串\n",
    "print(datasets[8]['whole_func_string'])\n",
    "# 当传入的是一个数组时，返回的依然是一个dict，但其中的value是一个列表\n",
    "print(datasets[8: 10]['whole_func_string'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(1, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(3, 2, nonlinearity='tanh', batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4865, -0.6551, -0.0722],\n",
       "         [ 0.0173,  0.3202, -0.1966]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1778,  0.4318],\n",
       "         [ 0.6170, -0.1327]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2245, 0.3032], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.7008,  0.3266], requires_grad=True)]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = list(rnn.parameters())\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = torch.randn(1, 1, 2)\n",
    "h0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 3)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9349,  0.8853],\n",
      "         [ 0.5682, -0.1969],\n",
      "         [ 0.6334,  0.5003]]], grad_fn=<TransposeBackward1>) tensor([[[0.6334, 0.5003]]], grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 2]), torch.Size([1, 1, 2]))"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, h = rnn(x, h0)\n",
    "print(o, h)\n",
    "o.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0624,  0.3718],\n",
      "         [-2.3894,  0.3730],\n",
      "         [ 1.3751,  0.0979]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7866,  0.3556],\n",
       "         [-0.9833,  0.3566],\n",
       "         [ 0.8798,  0.0976]]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x @ k[0].T + k[2] + k[3] + h0 @ k[1].T)\n",
    "F.tanh(x @ k[0].T + k[2] + k[3] + h0 @ k[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        re = []\n",
    "        # B batch_size,\n",
    "        # T sequence length,\n",
    "        # C number of channels.\n",
    "        B, T, C = x.shape\n",
    "        x = x.transpose(0, 1) # (T, B, C)\n",
    "        seq_len = x.shape[0]\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(B)\n",
    "        for i in range(seq_len):\n",
    "            # x[i]: (B, C); hidden: (B, hidden_size)\n",
    "            combined = torch.cat((x[i], hidden), dim=1)\n",
    "            hidden = F.relu(self.i2h(combined))  # (B, hidden_size)\n",
    "            re.append(hidden)\n",
    "        result_tensor = torch.stack(re, 0)  # (T, B, hidden_size)\n",
    "        return result_tensor.transpose(0, 1)\n",
    "    \n",
    "    def init_hidden(self, B):\n",
    "        return torch.zeros(B, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5772, 0.0000],\n",
      "         [1.0884, 0.2372],\n",
      "         [0.0000, 0.2318]]], grad_fn=<TransposeBackward1>) torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(3, 2, nonlinearity='relu', batch_first=True)\n",
    "h0 = torch.randn(1, 1, 2)\n",
    "x = torch.randn(1, 3, 3)\n",
    "o, h = rnn(x, h0)\n",
    "print(o, o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RNN(3, 2)\n",
    "k = list(rnn.parameters())\n",
    "m.i2h.weight = nn.Parameter(torch.cat((k[0], k[1]), dim=1))\n",
    "m.i2h.bias = nn.Parameter(k[2] + k[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5772, 0.0000],\n",
      "         [1.0884, 0.2372],\n",
      "         [0.0000, 0.2318]]], grad_fn=<TransposeBackward0>) torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "o = m(x, h0.squeeze(0))\n",
    "print(o, o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"codeparrot/github-code\", \"Python-all\", streaming=True, split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ds.filter(lambda x: x['repo_name'] == 'pytorch/pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = load_dataset('codeparrot/github-code', languages=[\"Python\"], licenses=['bsd-3-clause'],\n",
    "                       streaming=True, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': '# The purpose of these tests are to ensure that calling ufuncs with quantities\\n# returns quantities with the right units, or raises exceptions.\\n\\nimport warnings\\n\\nimport pytest\\nimport numpy as np\\nfrom numpy.testing.utils import assert_allclose\\n\\nfrom ... import units as u\\nfrom ...tests.helper import raises\\nfrom ...extern.six.moves import zip\\nfrom ...utils.compat import NUMPY_LT_1_13\\n\\n\\nclass TestUfuncCoverage(object):\\n    \"\"\"Test that we cover all ufunc\\'s\"\"\"\\n\\n    def test_coverage(self):\\n        all_np_ufuncs = set([ufunc for ufunc in np.core.umath.__dict__.values()\\n                             if type(ufunc) == np.ufunc])\\n\\n        from .. import quantity_helper as qh\\n\\n        all_q_ufuncs = (qh.UNSUPPORTED_UFUNCS |\\n                        set(qh.UFUNC_HELPERS.keys()))\\n\\n        assert all_np_ufuncs - all_q_ufuncs == set([])\\n        assert all_q_ufuncs - all_np_ufuncs == set([])\\n\\n\\nclass TestQuantityTrigonometricFuncs(object):\\n    \"\"\"\\n    Test trigonometric functions\\n    \"\"\"\\n\\n    def test_sin_scalar(self):\\n        q = np.sin(30. * u.degree)\\n        assert q.unit == u.dimensionless_unscaled\\n        assert_allclose(q.value, 0.5)\\n\\n    def test_sin_array(self):\\n        q = np.sin(np.array([0., np.pi / 4., np.pi / 2.]) * u.radian)\\n        assert q.unit == u.dimensionless_unscaled\\n        assert_allclose(q.value,\\n                        np.array([0., 1. / np.sqrt(2.), 1.]), atol=1.e-15)\\n\\n    def test_arcsin_scalar(self):\\n        q1 = 30. * u.degree\\n        q2 = np.arcsin(np.sin(q1)).to(q1.unit)\\n        assert_allclose(q1.value, q2.value)\\n\\n    def test_arcsin_array(self):\\n        q1 = np.array([0., np.pi / 4., np.pi / 2.]) * u.radian\\n        q2 = np.arcsin(np.sin(q1)).to(q1.unit)\\n        assert_allclose(q1.value, q2.value)\\n\\n    def test_sin_invalid_units(self):\\n        with pytest.raises(TypeError) as exc:\\n            np.sin(3. * u.m)\\n        assert exc.value.args[0] == (\"Can only apply \\'sin\\' function \"\\n                                     \"to quantities with angle units\")\\n\\n    def test_arcsin_invalid_units(self):\\n        with pytest.raises(TypeError) as exc:\\n            np.arcsin(3. * u.m)\\n        assert exc.value.args[0] == (\"Can only apply \\'arcsin\\' function to \"\\n                                     \"dimensionless quantities\")\\n\\n    def test_arcsin_no_warning_on_unscaled_quantity(self):\\n        a = 15 * u.kpc\\n        b = 27 * u.pc\\n\\n        with warnings.catch_warnings():\\n            warnings.filterwarnings(\\'error\\')\\n            np.arcsin(b/a)\\n\\n    def test_cos_scalar(self):\\n        q = np.cos(np.pi / 3. * u.radian)\\n        assert q.unit == u.dimensionless_unscaled\\n        assert_allclose(q.value, 0.5)\\n\\n    def test_cos_array(self):\\n        q = np.cos(np.array([0., np.pi / 4., np.pi / 2.]) * u.radian)\\n        assert q.unit == u.dimensionless_unscaled\\n        assert_allclose(q.value,\\n                        np.array([1., 1. / np.sqrt(2.), 0.]), atol=1.e-15)\\n\\n    def test_arccos_scalar(self):\\n        q1 = np.pi / 3. * u.radian\\n        q2 = np.arccos(np.cos(q1)).to(q1.unit)\\n        assert_allclose(q1.value, q2.value)\\n\\n    def test_arccos_array(self):\\n        q1 = np.array([0., np.pi / 4., np.pi / 2.]) * u.radian\\n        q2 = np.arccos(np.cos(q1)).to(q1.unit)\\n        assert_allclose(q1.value, q2.value)\\n\\n    def test_cos_invalid_units(self):\\n        with pytest.raises(TypeError) as exc:\\n            np.cos(3. * u.s)\\n        assert exc.value.args[0] == (\"Can only apply \\'cos\\' function \"\\n                                     \"to quantities with angle units\")\\n\\n    def test_arccos_invalid_units(self):\\n        with pytest.raises(TypeError) as exc:\\n            np.arccos(3. * u.s)\\n        assert exc.value.args[0] == (\"Can only apply \\'arccos\\' function to \"\\n                                     \"dimensionless quantities\")\\n\\n    def test_tan_scalar(self):\\n        q = np.tan(np.pi / 3. * u.radian)\\n        assert q.unit == u.dimensionless_unscaled\\n        assert_allclose(q.value, np.sqrt(3.))\\n\\n    def test_tan_array(self):\\n        q = np.tan(np.array([0., 45., 135., 180.]) * u.degree)\\n        assert q.unit == u.dimensionless_unscaled\\n        assert_allclose(q.value,\\n                        np.array([0., 1., -1., 0.]), atol=1.e-15)\\n\\n    def test_arctan_scalar(self):\\n        q = np.pi / 3. * u.radian\\n        assert np.arctan(np.tan(q))\\n\\n    def test_arctan_array(self):\\n        q = np.array([10., 30., 70., 80.]) * u.degree\\n        assert_allclose(np.arctan(np.tan(q)).to_value(q.unit), q.value)\\n\\n    def test_tan_invalid_units(self):\\n        with pytest.raises(TypeError) as exc:\\n            np.tan(np.array([1, 2, 3]) * u.N)\\n        assert exc.value.args[0] == (\"Can only apply \\'tan\\' function \"\\n                                     \"to quantities with angle units\")\\n\\n    def test_arctan_invalid_units(self):\\n        with pytest.raises(TypeError) as exc:\\n            np.arctan(np.array([1, 2, 3]) * u.N)\\n        assert exc.value.args[0] == (\"Can only apply \\'arctan\\' function to \"\\n                                     \"dimensionless quantities\")\\n\\n    def test_arctan2_valid(self):\\n        q1 = np.array([10., 30., 70., 80.]) * u.m\\n        q2 = 2.0 * u.km\\n        assert np.arctan2(q1, q2).unit == u.radian\\n        assert_allclose(np.arctan2(q1, q2).value,\\n                        np.arctan2(q1.value, q2.to_value(q1.unit)))\\n        q3 = q1 / q2\\n        q4 = 1.\\n        at2 = np.arctan2(q3, q4)\\n        assert_allclose(at2.value, np.arctan2(q3.to_value(1), q4))\\n\\n    def test_arctan2_invalid(self):\\n        with pytest.raises(u.UnitsError) as exc:\\n            np.arctan2(np.array([1, 2, 3]) * u.N, 1. * u.s)\\n        assert \"compatible dimensions\" in exc.value.args[0]\\n        with pytest.raises(u.UnitsError) as exc:\\n            np.arctan2(np.array([1, 2, 3]) * u.N, 1.)\\n        assert \"dimensionless quantities when other arg\" in exc.value.args[0]\\n\\n    def test_radians(self):\\n\\n        q1 = np.deg2rad(180. * u.degree)\\n        assert_allclose(q1.value, np.pi)\\n        assert q1.unit == u.radian\\n\\n        q2 = np.radians(180. * u.degree)\\n        assert_allclose(q2.value, np.pi)\\n        assert q2.unit == u.radian\\n\\n        # the following doesn\\'t make much sense in terms of the name of the\\n        # routine, but we check it gives the correct result.\\n        q3 = np.deg2rad(3. * u.radian)\\n        assert_allclose(q3.value, 3.)\\n        assert q3.unit == u.radian\\n\\n        q4 = np.radians(3. * u.radian)\\n        assert_allclose(q4.value, 3.)\\n        assert q4.unit == u.radian\\n\\n        with pytest.raises(TypeError):\\n            np.deg2rad(3. * u.m)\\n\\n        with pytest.raises(TypeError):\\n            np.radians(3. * u.m)\\n\\n    def test_degrees(self):\\n\\n        # the following doesn\\'t make much sense in terms of the name of the\\n        # routine, but we check it gives the correct result.\\n        q1 = np.rad2deg(60. * u.degree)\\n        assert_allclose(q1.value, 60.)\\n        assert q1.unit == u.degree\\n\\n        q2 = np.degrees(60. * u.degree)\\n        assert_allclose(q2.value, 60.)\\n        assert q2.unit == u.degree\\n\\n        q3 = np.rad2deg(np.pi * u.radian)\\n        assert_allclose(q3.value, 180.)\\n        assert q3.unit == u.degree\\n\\n        q4 = np.degrees(np.pi * u.radian)\\n        assert_allclose(q4.value, 180.)\\n        assert q4.unit == u.degree\\n\\n        with pytest.raises(TypeError):\\n            np.rad2deg(3. * u.m)\\n\\n        with pytest.raises(TypeError):\\n            np.degrees(3. * u.m)\\n\\n\\nclass TestQuantityMathFuncs(object):\\n    \"\"\"\\n    Test other mathematical functions\\n    \"\"\"\\n\\n    def test_multiply_scalar(self):\\n        assert np.multiply(4. * u.m, 2. / u.s) == 8. * u.m / u.s\\n        assert np.multiply(4. * u.m, 2.) == 8. * u.m\\n        assert np.multiply(4., 2. / u.s) == 8. / u.s\\n\\n    def test_multiply_array(self):\\n        assert np.all(np.multiply(np.arange(3.) * u.m, 2. / u.s) ==\\n                      np.arange(0, 6., 2.) * u.m / u.s)\\n\\n    @pytest.mark.parametrize(\\'function\\', (np.divide, np.true_divide))\\n    def test_divide_scalar(self, function):\\n        assert function(4. * u.m, 2. * u.s) == function(4., 2.) * u.m / u.s\\n        assert function(4. * u.m, 2.) == function(4., 2.) * u.m\\n        assert function(4., 2. * u.s) == function(4., 2.) / u.s\\n\\n    @pytest.mark.parametrize(\\'function\\', (np.divide, np.true_divide))\\n    def test_divide_array(self, function):\\n        assert np.all(function(np.arange(3.) * u.m, 2. * u.s) ==\\n                      function(np.arange(3.), 2.) * u.m / u.s)\\n\\n    def test_floor_divide_remainder_and_divmod(self):\\n        inch = u.Unit(0.0254 * u.m)\\n        dividend = np.array([1., 2., 3.]) * u.m\\n        divisor = np.array([3., 4., 5.]) * inch\\n        quotient = dividend // divisor\\n        remainder = dividend % divisor\\n        assert_allclose(quotient.value, [13., 19., 23.])\\n        assert quotient.unit == u.dimensionless_unscaled\\n        assert_allclose(remainder.value, [0.0094, 0.0696, 0.079])\\n        assert remainder.unit == dividend.unit\\n        quotient2 = np.floor_divide(dividend, divisor)\\n        remainder2 = np.remainder(dividend, divisor)\\n        assert np.all(quotient2 == quotient)\\n        assert np.all(remainder2 == remainder)\\n        quotient3, remainder3 = divmod(dividend, divisor)\\n        assert np.all(quotient3 == quotient)\\n        assert np.all(remainder3 == remainder)\\n\\n        with pytest.raises(TypeError):\\n            divmod(dividend, u.km)\\n\\n        with pytest.raises(TypeError):\\n            dividend // u.km\\n\\n        with pytest.raises(TypeError):\\n            dividend % u.km\\n\\n        if hasattr(np, \\'divmod\\'):  # not NUMPY_LT_1_13\\n            quotient4, remainder4 = np.divmod(dividend, divisor)\\n            assert np.all(quotient4 == quotient)\\n            assert np.all(remainder4 == remainder)\\n            with pytest.raises(TypeError):\\n                np.divmod(dividend, u.km)\\n\\n    def test_sqrt_scalar(self):\\n        assert np.sqrt(4. * u.m) == 2. * u.m ** 0.5\\n\\n    def test_sqrt_array(self):\\n        assert np.all(np.sqrt(np.array([1., 4., 9.]) * u.m)\\n                      == np.array([1., 2., 3.]) * u.m ** 0.5)\\n\\n    def test_square_scalar(self):\\n        assert np.square(4. * u.m) == 16. * u.m ** 2\\n\\n    def test_square_array(self):\\n        assert np.all(np.square(np.array([1., 2., 3.]) * u.m)\\n                      == np.array([1., 4., 9.]) * u.m ** 2)\\n\\n    def test_reciprocal_scalar(self):\\n        assert np.reciprocal(4. * u.m) == 0.25 / u.m\\n\\n    def test_reciprocal_array(self):\\n        assert np.all(np.reciprocal(np.array([1., 2., 4.]) * u.m)\\n                      == np.array([1., 0.5, 0.25]) / u.m)\\n\\n    # cbrt only introduced in numpy 1.10\\n    # heaviside only introduced in numpy 1.13\\n    @pytest.mark.skipif(\"not hasattr(np, \\'heaviside\\')\")\\n    def test_heaviside_scalar(self):\\n        assert np.heaviside(0. * u.m, 0.5) == 0.5 * u.dimensionless_unscaled\\n        assert np.heaviside(0. * u.s,\\n                            25 * u.percent) == 0.25 * u.dimensionless_unscaled\\n        assert np.heaviside(2. * u.J, 0.25) == 1. * u.dimensionless_unscaled\\n\\n    @pytest.mark.skipif(\"not hasattr(np, \\'heaviside\\')\")\\n    def test_heaviside_array(self):\\n        values = np.array([-1., 0., 0., +1.])\\n        halfway = np.array([0.75, 0.25, 0.75, 0.25]) * u.dimensionless_unscaled\\n        assert np.all(np.heaviside(values * u.m,\\n                                   halfway * u.dimensionless_unscaled) ==\\n                      [0, 0.25, 0.75, +1.] * u.dimensionless_unscaled)\\n\\n    @pytest.mark.skipif(\"not hasattr(np, \\'cbrt\\')\")\\n    def test_cbrt_scalar(self):\\n        assert np.cbrt(8. * u.m**3) == 2. * u.m\\n\\n    @pytest.mark.skipif(\"not hasattr(np, \\'cbrt\\')\")\\n    def test_cbrt_array(self):\\n        # Calculate cbrt on both sides since on Windows the cube root of 64\\n        # does not exactly equal 4.  See 4388.\\n        values = np.array([1., 8., 64.])\\n        assert np.all(np.cbrt(values * u.m**3) ==\\n                      np.cbrt(values) * u.m)\\n\\n    def test_power_scalar(self):\\n        assert np.power(4. * u.m, 2.) == 16. * u.m ** 2\\n        assert np.power(4., 200. * u.cm / u.m) == \\\\\\n            u.Quantity(16., u.dimensionless_unscaled)\\n        # regression check on #1696\\n        assert np.power(4. * u.m, 0.) == 1. * u.dimensionless_unscaled\\n\\n    def test_power_array(self):\\n        assert np.all(np.power(np.array([1., 2., 3.]) * u.m, 3.)\\n                      == np.array([1., 8., 27.]) * u.m ** 3)\\n        # regression check on #1696\\n        assert np.all(np.power(np.arange(4.) * u.m, 0.) ==\\n                      1. * u.dimensionless_unscaled)\\n\\n    # float_power only introduced in numpy 1.12\\n    @pytest.mark.skipif(\"not hasattr(np, \\'float_power\\')\")\\n    def test_float_power_array(self):\\n        assert np.all(np.float_power(np.array([1., 2., 3.]) * u.m, 3.)\\n                      == np.array([1., 8., 27.]) * u.m ** 3)\\n        # regression check on #1696\\n        assert np.all(np.float_power(np.arange(4.) * u.m, 0.) ==\\n                      1. * u.dimensionless_unscaled)\\n\\n    @raises(ValueError)\\n    def test_power_array_array(self):\\n        np.power(4. * u.m, [2., 4.])\\n\\n    @raises(ValueError)\\n    def test_power_array_array2(self):\\n        np.power([2., 4.] * u.m, [2., 4.])\\n\\n    def test_power_array_array3(self):\\n        # Identical unit fractions are converted automatically to dimensionless\\n        # and should be allowed as base for np.power: #4764\\n        q = [2., 4.] * u.m / u.m\\n        powers = [2., 4.]\\n        res = np.power(q, powers)\\n        assert np.all(res.value == q.value ** powers)\\n        assert res.unit == u.dimensionless_unscaled\\n        # The same holds for unit fractions that are scaled dimensionless.\\n        q2 = [2., 4.] * u.m / u.cm\\n        # Test also against different types of exponent\\n        for cls in (list, tuple, np.array, np.ma.array, u.Quantity):\\n            res2 = np.power(q2, cls(powers))\\n            assert np.all(res2.value == q2.to_value(1) ** powers)\\n            assert res2.unit == u.dimensionless_unscaled\\n        # Though for single powers, we keep the composite unit.\\n        res3 = q2 ** 2\\n        assert np.all(res3.value == q2.value ** 2)\\n        assert res3.unit == q2.unit ** 2\\n        assert np.all(res3 == q2 ** [2, 2])\\n\\n    def test_power_invalid(self):\\n        with pytest.raises(TypeError) as exc:\\n            np.power(3., 4. * u.m)\\n        assert \"raise something to a dimensionless\" in exc.value.args[0]\\n\\n    def test_copysign_scalar(self):\\n        assert np.copysign(3 * u.m, 1.) == 3. * u.m\\n        assert np.copysign(3 * u.m, 1. * u.s) == 3. * u.m\\n        assert np.copysign(3 * u.m, -1.) == -3. * u.m\\n        assert np.copysign(3 * u.m, -1. * u.s) == -3. * u.m\\n\\n    def test_copysign_array(self):\\n        assert np.all(np.copysign(np.array([1., 2., 3.]) * u.s, -1.) == -np.array([1., 2., 3.]) * u.s)\\n        assert np.all(np.copysign(np.array([1., 2., 3.]) * u.s, -1. * u.m) == -np.array([1., 2., 3.]) * u.s)\\n        assert np.all(np.copysign(np.array([1., 2., 3.]) * u.s, np.array([-2., 2., -4.]) * u.m) == np.array([-1., 2., -3.]) * u.s)\\n\\n        q = np.copysign(np.array([1., 2., 3.]), -3 * u.m)\\n        assert np.all(q == np.array([-1., -2., -3.]))\\n        assert not isinstance(q, u.Quantity)\\n\\n    def test_ldexp_scalar(self):\\n        assert np.ldexp(4. * u.m, 2) == 16. * u.m\\n\\n    def test_ldexp_array(self):\\n        assert np.all(np.ldexp(np.array([1., 2., 3.]) * u.m, [3, 2, 1])\\n                      == np.array([8., 8., 6.]) * u.m)\\n\\n    def test_ldexp_invalid(self):\\n        with pytest.raises(TypeError):\\n            np.ldexp(3. * u.m, 4.)\\n\\n        with pytest.raises(TypeError):\\n            np.ldexp(3., u.Quantity(4, u.m, dtype=int))\\n\\n    @pytest.mark.parametrize(\\'function\\', (np.exp, np.expm1, np.exp2,\\n                                          np.log, np.log2, np.log10, np.log1p))\\n    def test_exp_scalar(self, function):\\n        q = function(3. * u.m / (6. * u.m))\\n        assert q.unit == u.dimensionless_unscaled\\n        assert q.value == function(0.5)\\n\\n    @pytest.mark.parametrize(\\'function\\', (np.exp, np.expm1, np.exp2,\\n                                          np.log, np.log2, np.log10, np.log1p))\\n    def test_exp_array(self, function):\\n        q = function(np.array([2., 3., 6.]) * u.m / (6. * u.m))\\n        assert q.unit == u.dimensionless_unscaled\\n        assert np.all(q.value\\n                      == function(np.array([1. / 3., 1. / 2., 1.])))\\n        # should also work on quantities that can be made dimensionless\\n        q2 = function(np.array([2., 3., 6.]) * u.m / (6. * u.cm))\\n        assert q2.unit == u.dimensionless_unscaled\\n        assert_allclose(q2.value,\\n                        function(np.array([100. / 3., 100. / 2., 100.])))\\n\\n    @pytest.mark.parametrize(\\'function\\', (np.exp, np.expm1, np.exp2,\\n                                          np.log, np.log2, np.log10, np.log1p))\\n    def test_exp_invalid_units(self, function):\\n        # Can\\'t use exp() with non-dimensionless quantities\\n        with pytest.raises(TypeError) as exc:\\n            function(3. * u.m / u.s)\\n        assert exc.value.args[0] == (\"Can only apply \\'{0}\\' function to \"\\n                                     \"dimensionless quantities\"\\n                                     .format(function.__name__))\\n\\n    def test_modf_scalar(self):\\n        q = np.modf(9. * u.m / (600. * u.cm))\\n        assert q == (0.5 * u.dimensionless_unscaled,\\n                     1. * u.dimensionless_unscaled)\\n\\n    def test_modf_array(self):\\n        v = np.arange(10.) * u.m / (500. * u.cm)\\n        q = np.modf(v)\\n        n = np.modf(v.to_value(u.dimensionless_unscaled))\\n        assert q[0].unit == u.dimensionless_unscaled\\n        assert q[1].unit == u.dimensionless_unscaled\\n        assert all(q[0].value == n[0])\\n        assert all(q[1].value == n[1])\\n\\n    def test_frexp_scalar(self):\\n        q = np.frexp(3. * u.m / (6. * u.m))\\n        assert q == (np.array(0.5), np.array(0.0))\\n\\n    def test_frexp_array(self):\\n        q = np.frexp(np.array([2., 3., 6.]) * u.m / (6. * u.m))\\n        assert all((_q0, _q1) == np.frexp(_d) for _q0, _q1, _d\\n                   in zip(q[0], q[1], [1. / 3., 1. / 2., 1.]))\\n\\n    def test_frexp_invalid_units(self):\\n        # Can\\'t use prod() with non-dimensionless quantities\\n        with pytest.raises(TypeError) as exc:\\n            np.frexp(3. * u.m / u.s)\\n        assert exc.value.args[0] == (\"Can only apply \\'frexp\\' function to \"\\n                                     \"unscaled dimensionless quantities\")\\n\\n        # also does not work on quantities that can be made dimensionless\\n        with pytest.raises(TypeError) as exc:\\n            np.frexp(np.array([2., 3., 6.]) * u.m / (6. * u.cm))\\n        assert exc.value.args[0] == (\"Can only apply \\'frexp\\' function to \"\\n                                     \"unscaled dimensionless quantities\")\\n\\n    @pytest.mark.parametrize(\\'function\\', (np.logaddexp, np.logaddexp2))\\n    def test_dimensionless_twoarg_array(self, function):\\n        q = function(np.array([2., 3., 6.]) * u.m / (6. * u.cm), 1.)\\n        assert q.unit == u.dimensionless_unscaled\\n        assert_allclose(q.value,\\n                        function(np.array([100. / 3., 100. / 2., 100.]), 1.))\\n\\n    @pytest.mark.parametrize(\\'function\\', (np.logaddexp, np.logaddexp2))\\n    def test_dimensionless_twoarg_invalid_units(self, function):\\n\\n        with pytest.raises(TypeError) as exc:\\n            function(1. * u.km / u.s, 3. * u.m / u.s)\\n        assert exc.value.args[0] == (\"Can only apply \\'{0}\\' function to \"\\n                                     \"dimensionless quantities\"\\n                                     .format(function.__name__))\\n\\n\\nclass TestInvariantUfuncs(object):\\n\\n    # np.positive was only added in numpy 1.13.\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.absolute, np.fabs,\\n                                         np.conj, np.conjugate,\\n                                         np.negative, np.spacing, np.rint,\\n                                         np.floor, np.ceil] +\\n                             [np.positive] if hasattr(np, \\'positive\\') else [])\\n    def test_invariant_scalar(self, ufunc):\\n\\n        q_i = 4.7 * u.m\\n        q_o = ufunc(q_i)\\n        assert isinstance(q_o, u.Quantity)\\n        assert q_o.unit == q_i.unit\\n        assert q_o.value == ufunc(q_i.value)\\n\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.absolute, np.conjugate,\\n                                         np.negative, np.rint,\\n                                         np.floor, np.ceil])\\n    def test_invariant_array(self, ufunc):\\n\\n        q_i = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\\n        q_o = ufunc(q_i)\\n        assert isinstance(q_o, u.Quantity)\\n        assert q_o.unit == q_i.unit\\n        assert np.all(q_o.value == ufunc(q_i.value))\\n\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.add, np.subtract, np.hypot,\\n                                         np.maximum, np.minimum, np.nextafter,\\n                                         np.remainder, np.mod, np.fmod])\\n    def test_invariant_twoarg_scalar(self, ufunc):\\n\\n        q_i1 = 4.7 * u.m\\n        q_i2 = 9.4 * u.km\\n        q_o = ufunc(q_i1, q_i2)\\n        assert isinstance(q_o, u.Quantity)\\n        assert q_o.unit == q_i1.unit\\n        assert_allclose(q_o.value, ufunc(q_i1.value, q_i2.to_value(q_i1.unit)))\\n\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.add, np.subtract, np.hypot,\\n                                         np.maximum, np.minimum, np.nextafter,\\n                                         np.remainder, np.mod, np.fmod])\\n    def test_invariant_twoarg_array(self, ufunc):\\n\\n        q_i1 = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\\n        q_i2 = np.array([10., -5., 1.e6]) * u.g / u.us\\n        q_o = ufunc(q_i1, q_i2)\\n        assert isinstance(q_o, u.Quantity)\\n        assert q_o.unit == q_i1.unit\\n        assert_allclose(q_o.value, ufunc(q_i1.value, q_i2.to_value(q_i1.unit)))\\n\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.add, np.subtract, np.hypot,\\n                                         np.maximum, np.minimum, np.nextafter,\\n                                         np.remainder, np.mod, np.fmod])\\n    def test_invariant_twoarg_one_arbitrary(self, ufunc):\\n\\n        q_i1 = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\\n        arbitrary_unit_value = np.array([0.])\\n        q_o = ufunc(q_i1, arbitrary_unit_value)\\n        assert isinstance(q_o, u.Quantity)\\n        assert q_o.unit == q_i1.unit\\n        assert_allclose(q_o.value, ufunc(q_i1.value, arbitrary_unit_value))\\n\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.add, np.subtract, np.hypot,\\n                                         np.maximum, np.minimum, np.nextafter,\\n                                         np.remainder, np.mod, np.fmod])\\n    def test_invariant_twoarg_invalid_units(self, ufunc):\\n\\n        q_i1 = 4.7 * u.m\\n        q_i2 = 9.4 * u.s\\n        with pytest.raises(u.UnitsError) as exc:\\n            ufunc(q_i1, q_i2)\\n        assert \"compatible dimensions\" in exc.value.args[0]\\n\\n\\nclass TestComparisonUfuncs(object):\\n\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.greater, np.greater_equal,\\n                                         np.less, np.less_equal,\\n                                         np.not_equal, np.equal])\\n    def test_comparison_valid_units(self, ufunc):\\n        q_i1 = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\\n        q_i2 = np.array([10., -5., 1.e6]) * u.g / u.Ms\\n        q_o = ufunc(q_i1, q_i2)\\n        assert not isinstance(q_o, u.Quantity)\\n        assert q_o.dtype == np.bool\\n        assert np.all(q_o == ufunc(q_i1.value, q_i2.to_value(q_i1.unit)))\\n        q_o2 = ufunc(q_i1 / q_i2, 2.)\\n        assert not isinstance(q_o2, u.Quantity)\\n        assert q_o2.dtype == np.bool\\n        assert np.all(q_o2 == ufunc((q_i1 / q_i2)\\n                                    .to_value(u.dimensionless_unscaled), 2.))\\n        # comparison with 0., inf, nan is OK even for dimensional quantities\\n        for arbitrary_unit_value in (0., np.inf, np.nan):\\n            ufunc(q_i1, arbitrary_unit_value)\\n            ufunc(q_i1, arbitrary_unit_value*np.ones(len(q_i1)))\\n        # and just for completeness\\n        ufunc(q_i1, np.array([0., np.inf, np.nan]))\\n\\n    @pytest.mark.parametrize((\\'ufunc\\'), [np.greater, np.greater_equal,\\n                                         np.less, np.less_equal,\\n                                         np.not_equal, np.equal])\\n    def test_comparison_invalid_units(self, ufunc):\\n        q_i1 = 4.7 * u.m\\n        q_i2 = 9.4 * u.s\\n        with pytest.raises(u.UnitsError) as exc:\\n            ufunc(q_i1, q_i2)\\n        assert \"compatible dimensions\" in exc.value.args[0]\\n\\n\\nclass TestInplaceUfuncs(object):\\n\\n    @pytest.mark.parametrize((\\'value\\'), [1., np.arange(10.)])\\n    def test_one_argument_ufunc_inplace(self, value):\\n        # without scaling\\n        s = value * u.rad\\n        check = s\\n        np.sin(s, out=s)\\n        assert check is s\\n        assert check.unit == u.dimensionless_unscaled\\n        # with scaling\\n        s2 = (value * u.rad).to(u.deg)\\n        check2 = s2\\n        np.sin(s2, out=s2)\\n        assert check2 is s2\\n        assert check2.unit == u.dimensionless_unscaled\\n        assert_allclose(s.value, s2.value)\\n\\n    @pytest.mark.parametrize((\\'value\\'), [1., np.arange(10.)])\\n    def test_one_argument_ufunc_inplace_2(self, value):\\n        \"\"\"Check inplace works with non-quantity input and quantity output\"\"\"\\n        s = value * u.m\\n        check = s\\n        np.absolute(value, out=s)\\n        assert check is s\\n        assert np.all(check.value == np.absolute(value))\\n        assert check.unit is u.dimensionless_unscaled\\n        np.sqrt(value, out=s)\\n        assert check is s\\n        assert np.all(check.value == np.sqrt(value))\\n        assert check.unit is u.dimensionless_unscaled\\n        np.exp(value, out=s)\\n        assert check is s\\n        assert np.all(check.value == np.exp(value))\\n        assert check.unit is u.dimensionless_unscaled\\n        np.arcsin(value/10., out=s)\\n        assert check is s\\n        assert np.all(check.value == np.arcsin(value/10.))\\n        assert check.unit is u.radian\\n\\n    @pytest.mark.parametrize((\\'value\\'), [1., np.arange(10.)])\\n    def test_one_argument_two_output_ufunc_inplace(self, value):\\n        v = 100. * value * u.cm / u.m\\n        v_copy = v.copy()\\n        tmp = v.copy()\\n        check = v\\n        np.modf(v, tmp, v)  # cannot use out1,out2 keywords with numpy 1.7\\n        assert check is v\\n        assert check.unit == u.dimensionless_unscaled\\n        v2 = v_copy.to(u.dimensionless_unscaled)\\n        check2 = v2\\n        np.modf(v2, tmp, v2)\\n        assert check2 is v2\\n        assert check2.unit == u.dimensionless_unscaled\\n        # can also replace in last position if no scaling is needed\\n        v3 = v_copy.to(u.dimensionless_unscaled)\\n        check3 = v3\\n        np.modf(v3, v3, tmp)\\n        assert check3 is v3\\n        assert check3.unit == u.dimensionless_unscaled\\n        # in np<1.13, without __array_ufunc__, one cannot replace input with\\n        # first output when scaling\\n        v4 = v_copy.copy()\\n        if NUMPY_LT_1_13:\\n            with pytest.raises(TypeError):\\n                np.modf(v4, v4, tmp)\\n        else:\\n            check4 = v4\\n            np.modf(v4, v4, tmp)\\n            assert check4 is v4\\n            assert check4.unit == u.dimensionless_unscaled\\n\\n    @pytest.mark.parametrize((\\'value\\'), [1., np.arange(10.)])\\n    def test_two_argument_ufunc_inplace_1(self, value):\\n        s = value * u.cycle\\n        check = s\\n        s /= 2.\\n        assert check is s\\n        assert np.all(check.value == value / 2.)\\n        s /= u.s\\n        assert check is s\\n        assert check.unit == u.cycle / u.s\\n        s *= 2. * u.s\\n        assert check is s\\n        assert np.all(check == value * u.cycle)\\n\\n    @pytest.mark.parametrize((\\'value\\'), [1., np.arange(10.)])\\n    def test_two_argument_ufunc_inplace_2(self, value):\\n        s = value * u.cycle\\n        check = s\\n        np.arctan2(s, s, out=s)\\n        assert check is s\\n        assert check.unit == u.radian\\n        with pytest.raises(u.UnitsError):\\n            s += 1. * u.m\\n        assert check is s\\n        assert check.unit == u.radian\\n        np.arctan2(1. * u.deg, s, out=s)\\n        assert check is s\\n        assert check.unit == u.radian\\n        np.add(1. * u.deg, s, out=s)\\n        assert check is s\\n        assert check.unit == u.deg\\n        np.multiply(2. / u.s, s, out=s)\\n        assert check is s\\n        assert check.unit == u.deg / u.s\\n\\n    def test_two_argument_ufunc_inplace_3(self):\\n        s = np.array([1., 2., 3.]) * u.dimensionless_unscaled\\n        np.add(np.array([1., 2., 3.]), np.array([1., 2., 3.]) * 2., out=s)\\n        assert np.all(s.value == np.array([3., 6., 9.]))\\n        assert s.unit is u.dimensionless_unscaled\\n        np.arctan2(np.array([1., 2., 3.]), np.array([1., 2., 3.]) * 2., out=s)\\n        assert_allclose(s.value, np.arctan2(1., 2.))\\n        assert s.unit is u.radian\\n\\n    @pytest.mark.skipif(NUMPY_LT_1_13, reason=\"numpy >=1.13 required.\")\\n    @pytest.mark.parametrize((\\'value\\'), [1., np.arange(10.)])\\n    def test_two_argument_two_output_ufunc_inplace(self, value):\\n        v = value * u.m\\n        divisor = 70.*u.cm\\n        v1 = v.copy()\\n        tmp = v.copy()\\n        check = np.divmod(v1, divisor, out=(tmp, v1))\\n        assert check[0] is tmp and check[1] is v1\\n        assert tmp.unit == u.dimensionless_unscaled\\n        assert v1.unit == v.unit\\n        v2 = v.copy()\\n        check2 = np.divmod(v2, divisor, out=(v2, tmp))\\n        assert check2[0] is v2 and check2[1] is tmp\\n        assert v2.unit == u.dimensionless_unscaled\\n        assert tmp.unit == v.unit\\n        v3a = v.copy()\\n        v3b = v.copy()\\n        check3 = np.divmod(v3a, divisor, out=(v3a, v3b))\\n        assert check3[0] is v3a and check3[1] is v3b\\n        assert v3a.unit == u.dimensionless_unscaled\\n        assert v3b.unit == v.unit\\n\\n    def test_ufunc_inplace_non_contiguous_data(self):\\n        # ensure inplace works also for non-contiguous data (closes #1834)\\n        s = np.arange(10.) * u.m\\n        s_copy = s.copy()\\n        s2 = s[::2]\\n        s2 += 1. * u.cm\\n        assert np.all(s[::2] > s_copy[::2])\\n        assert np.all(s[1::2] == s_copy[1::2])\\n\\n    def test_ufunc_inplace_non_standard_dtype(self):\\n        \"\"\"Check that inplace operations check properly for casting.\\n\\n        First two tests that check that float32 is kept close #3976.\\n        \"\"\"\\n        a1 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.float32)\\n        a1 *= np.float32(10)\\n        assert a1.unit is u.m\\n        assert a1.dtype == np.float32\\n        a2 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.float32)\\n        a2 += (20.*u.km)\\n        assert a2.unit is u.m\\n        assert a2.dtype == np.float32\\n        # For integer, in-place only works if no conversion is done.\\n        a3 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.int32)\\n        a3 += u.Quantity(10, u.m, dtype=np.int64)\\n        assert a3.unit is u.m\\n        assert a3.dtype == np.int32\\n        a4 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.int32)\\n        with pytest.raises(TypeError):\\n            a4 += u.Quantity(10, u.mm, dtype=np.int64)\\n\\n\\n@pytest.mark.xfail(\"NUMPY_LT_1_13\")\\nclass TestUfuncAt(object):\\n    \"\"\"Test that \\'at\\' method for ufuncs (calculates in-place at given indices)\\n\\n    For Quantities, since calculations are in-place, it makes sense only\\n    if the result is still a quantity, and if the unit does not have to change\\n    \"\"\"\\n\\n    def test_one_argument_ufunc_at(self):\\n        q = np.arange(10.) * u.m\\n        i = np.array([1, 2])\\n        qv = q.value.copy()\\n        np.negative.at(q, i)\\n        np.negative.at(qv, i)\\n        assert np.all(q.value == qv)\\n        assert q.unit is u.m\\n\\n        # cannot change from quantity to bool array\\n        with pytest.raises(TypeError):\\n            np.isfinite.at(q, i)\\n\\n        # for selective in-place, cannot change the unit\\n        with pytest.raises(u.UnitsError):\\n            np.square.at(q, i)\\n\\n        # except if the unit does not change (i.e., dimensionless)\\n        d = np.arange(10.) * u.dimensionless_unscaled\\n        dv = d.value.copy()\\n        np.square.at(d, i)\\n        np.square.at(dv, i)\\n        assert np.all(d.value == dv)\\n        assert d.unit is u.dimensionless_unscaled\\n\\n        d = np.arange(10.) * u.dimensionless_unscaled\\n        dv = d.value.copy()\\n        np.log.at(d, i)\\n        np.log.at(dv, i)\\n        assert np.all(d.value == dv)\\n        assert d.unit is u.dimensionless_unscaled\\n\\n        # also for sine it doesn\\'t work, even if given an angle\\n        a = np.arange(10.) * u.radian\\n        with pytest.raises(u.UnitsError):\\n            np.sin.at(a, i)\\n\\n        # except, for consistency, if we have made radian equivalent to\\n        # dimensionless (though hopefully it will never be needed)\\n        av = a.value.copy()\\n        with u.add_enabled_equivalencies(u.dimensionless_angles()):\\n            np.sin.at(a, i)\\n            np.sin.at(av, i)\\n            assert_allclose(a.value, av)\\n\\n            # but we won\\'t do double conversion\\n            ad = np.arange(10.) * u.degree\\n            with pytest.raises(u.UnitsError):\\n                np.sin.at(ad, i)\\n\\n    def test_two_argument_ufunc_at(self):\\n        s = np.arange(10.) * u.m\\n        i = np.array([1, 2])\\n        check = s.value.copy()\\n        np.add.at(s, i, 1.*u.km)\\n        np.add.at(check, i, 1000.)\\n        assert np.all(s.value == check)\\n        assert s.unit is u.m\\n\\n        with pytest.raises(u.UnitsError):\\n            np.add.at(s, i, 1.*u.s)\\n\\n        # also raise UnitsError if unit would have to be changed\\n        with pytest.raises(u.UnitsError):\\n            np.multiply.at(s, i, 1*u.s)\\n\\n        # but be fine if it does not\\n        s = np.arange(10.) * u.m\\n        check = s.value.copy()\\n        np.multiply.at(s, i, 2.*u.dimensionless_unscaled)\\n        np.multiply.at(check, i, 2)\\n        assert np.all(s.value == check)\\n        s = np.arange(10.) * u.m\\n        np.multiply.at(s, i, 2.)\\n        assert np.all(s.value == check)\\n\\n        # of course cannot change class of data either\\n        with pytest.raises(TypeError):\\n            np.greater.at(s, i, 1.*u.km)\\n\\n\\n@pytest.mark.xfail(\"NUMPY_LT_1_13\")\\nclass TestUfuncReduceReduceatAccumulate(object):\\n    \"\"\"Test \\'reduce\\', \\'reduceat\\' and \\'accumulate\\' methods for ufuncs\\n\\n    For Quantities, it makes sense only if the unit does not have to change\\n    \"\"\"\\n\\n    def test_one_argument_ufunc_reduce_accumulate(self):\\n        # one argument cannot be used\\n        s = np.arange(10.) * u.radian\\n        i = np.array([0, 5, 1, 6])\\n        with pytest.raises(ValueError):\\n            np.sin.reduce(s)\\n        with pytest.raises(ValueError):\\n            np.sin.accumulate(s)\\n        with pytest.raises(ValueError):\\n            np.sin.reduceat(s, i)\\n\\n    def test_two_argument_ufunc_reduce_accumulate(self):\\n        s = np.arange(10.) * u.m\\n        i = np.array([0, 5, 1, 6])\\n        check = s.value.copy()\\n        s_add_reduce = np.add.reduce(s)\\n        check_add_reduce = np.add.reduce(check)\\n        assert s_add_reduce.value == check_add_reduce\\n        assert s_add_reduce.unit is u.m\\n\\n        s_add_accumulate = np.add.accumulate(s)\\n        check_add_accumulate = np.add.accumulate(check)\\n        assert np.all(s_add_accumulate.value == check_add_accumulate)\\n        assert s_add_accumulate.unit is u.m\\n\\n        s_add_reduceat = np.add.reduceat(s, i)\\n        check_add_reduceat = np.add.reduceat(check, i)\\n        assert np.all(s_add_reduceat.value == check_add_reduceat)\\n        assert s_add_reduceat.unit is u.m\\n\\n        # reduce(at) or accumulate on comparisons makes no sense,\\n        # as intermediate result is not even a Quantity\\n        with pytest.raises(TypeError):\\n            np.greater.reduce(s)\\n\\n        with pytest.raises(TypeError):\\n            np.greater.accumulate(s)\\n\\n        with pytest.raises(TypeError):\\n            np.greater.reduceat(s, i)\\n\\n        # raise UnitsError if unit would have to be changed\\n        with pytest.raises(u.UnitsError):\\n            np.multiply.reduce(s)\\n\\n        with pytest.raises(u.UnitsError):\\n            np.multiply.accumulate(s)\\n\\n        with pytest.raises(u.UnitsError):\\n            np.multiply.reduceat(s, i)\\n\\n        # but be fine if it does not\\n        s = np.arange(10.) * u.dimensionless_unscaled\\n        check = s.value.copy()\\n        s_multiply_reduce = np.multiply.reduce(s)\\n        check_multiply_reduce = np.multiply.reduce(check)\\n        assert s_multiply_reduce.value == check_multiply_reduce\\n        assert s_multiply_reduce.unit is u.dimensionless_unscaled\\n        s_multiply_accumulate = np.multiply.accumulate(s)\\n        check_multiply_accumulate = np.multiply.accumulate(check)\\n        assert np.all(s_multiply_accumulate.value == check_multiply_accumulate)\\n        assert s_multiply_accumulate.unit is u.dimensionless_unscaled\\n        s_multiply_reduceat = np.multiply.reduceat(s, i)\\n        check_multiply_reduceat = np.multiply.reduceat(check, i)\\n        assert np.all(s_multiply_reduceat.value == check_multiply_reduceat)\\n        assert s_multiply_reduceat.unit is u.dimensionless_unscaled\\n\\n\\n@pytest.mark.xfail(\"NUMPY_LT_1_13\")\\nclass TestUfuncOuter(object):\\n    \"\"\"Test \\'outer\\' methods for ufuncs\\n\\n    Just a few spot checks, since it uses the same code as the regular\\n    ufunc call\\n    \"\"\"\\n\\n    def test_one_argument_ufunc_outer(self):\\n        # one argument cannot be used\\n        s = np.arange(10.) * u.radian\\n        with pytest.raises(ValueError):\\n            np.sin.outer(s)\\n\\n    def test_two_argument_ufunc_outer(self):\\n        s1 = np.arange(10.) * u.m\\n        s2 = np.arange(2.) * u.s\\n        check1 = s1.value\\n        check2 = s2.value\\n        s12_multiply_outer = np.multiply.outer(s1, s2)\\n        check12_multiply_outer = np.multiply.outer(check1, check2)\\n        assert np.all(s12_multiply_outer.value == check12_multiply_outer)\\n        assert s12_multiply_outer.unit == s1.unit * s2.unit\\n\\n        # raise UnitsError if appropriate\\n        with pytest.raises(u.UnitsError):\\n            np.add.outer(s1, s2)\\n\\n        # but be fine if it does not\\n        s3 = np.arange(2.) * s1.unit\\n        check3 = s3.value\\n        s13_add_outer = np.add.outer(s1, s3)\\n        check13_add_outer = np.add.outer(check1, check3)\\n        assert np.all(s13_add_outer.value == check13_add_outer)\\n        assert s13_add_outer.unit is s1.unit\\n\\n        s13_greater_outer = np.greater.outer(s1, s3)\\n        check13_greater_outer = np.greater.outer(check1, check3)\\n        assert type(s13_greater_outer) is np.ndarray\\n        assert np.all(s13_greater_outer == check13_greater_outer)\\n',\n",
       " 'repo_name': 'AustereCuriosity/astropy',\n",
       " 'path': 'astropy/units/tests/test_quantity_ufuncs.py',\n",
       " 'language': 'Python',\n",
       " 'license': 'bsd-3-clause',\n",
       " 'size': 38162}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(rawdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_name': 'proycon/pynlpl',\n",
       " 'func_path_in_repository': 'pynlpl/formats/folia.py',\n",
       " 'func_name': 'AbstractElement.findreplaceables',\n",
       " 'whole_func_string': 'def findreplaceables(Class, parent, set=None,**kwargs):\\n        \"\"\"Internal method to find replaceable elements. Auxiliary function used by :meth:`AbstractElement.replace`. Can be overriden for more fine-grained control.\"\"\"\\n        return list(parent.select(Class,set,False))',\n",
       " 'language': 'python',\n",
       " 'func_code_string': 'def findreplaceables(Class, parent, set=None,**kwargs):\\n        \"\"\"Internal method to find replaceable elements. Auxiliary function used by :meth:`AbstractElement.replace`. Can be overriden for more fine-grained control.\"\"\"\\n        return list(parent.select(Class,set,False))',\n",
       " 'func_code_tokens': ['def',\n",
       "  'findreplaceables',\n",
       "  '(',\n",
       "  'Class',\n",
       "  ',',\n",
       "  'parent',\n",
       "  ',',\n",
       "  'set',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  '*',\n",
       "  '*',\n",
       "  'kwargs',\n",
       "  ')',\n",
       "  ':',\n",
       "  'return',\n",
       "  'list',\n",
       "  '(',\n",
       "  'parent',\n",
       "  '.',\n",
       "  'select',\n",
       "  '(',\n",
       "  'Class',\n",
       "  ',',\n",
       "  'set',\n",
       "  ',',\n",
       "  'False',\n",
       "  ')',\n",
       "  ')'],\n",
       " 'func_documentation_string': 'Internal method to find replaceable elements. Auxiliary function used by :meth:`AbstractElement.replace`. Can be overriden for more fine-grained control.',\n",
       " 'func_documentation_tokens': ['Internal',\n",
       "  'method',\n",
       "  'to',\n",
       "  'find',\n",
       "  'replaceable',\n",
       "  'elements',\n",
       "  '.',\n",
       "  'Auxiliary',\n",
       "  'function',\n",
       "  'used',\n",
       "  'by',\n",
       "  ':',\n",
       "  'meth',\n",
       "  ':',\n",
       "  'AbstractElement',\n",
       "  '.',\n",
       "  'replace',\n",
       "  '.',\n",
       "  'Can',\n",
       "  'be',\n",
       "  'overriden',\n",
       "  'for',\n",
       "  'more',\n",
       "  'fine',\n",
       "  '-',\n",
       "  'grained',\n",
       "  'control',\n",
       "  '.'],\n",
       " 'split_name': 'train',\n",
       " 'func_code_url': 'https://github.com/proycon/pynlpl/blob/7707f69a91caaa6cde037f0d0379f1d42500a68b/pynlpl/formats/folia.py#L1766-L1768'}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")\n",
    "raw_datasets['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf28a7eaf32c4ca6bea7de42aeb6b72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/412178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = raw_datasets['train'].filter(lambda x: 'apache/spark' in x['repository_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apache/spark'}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(l['repository_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_name': 'apache/spark',\n",
       " 'func_path_in_repository': 'python/pyspark/rdd.py',\n",
       " 'func_name': 'RDD.lookup',\n",
       " 'whole_func_string': 'def lookup(self, key):\\n        \"\"\"\\n        Return the list of values in the RDD for key `key`. This operation\\n        is done efficiently if the RDD has a known partitioner by only\\n        searching the partition that the key maps to.\\n\\n        >>> l = range(1000)\\n        >>> rdd = sc.parallelize(zip(l, l), 10)\\n        >>> rdd.lookup(42)  # slow\\n        [42]\\n        >>> sorted = rdd.sortByKey()\\n        >>> sorted.lookup(42)  # fast\\n        [42]\\n        >>> sorted.lookup(1024)\\n        []\\n        >>> rdd2 = sc.parallelize([((\\'a\\', \\'b\\'), \\'c\\')]).groupByKey()\\n        >>> list(rdd2.lookup((\\'a\\', \\'b\\'))[0])\\n        [\\'c\\']\\n        \"\"\"\\n        values = self.filter(lambda kv: kv[0] == key).values()\\n\\n        if self.partitioner is not None:\\n            return self.ctx.runJob(values, lambda x: x, [self.partitioner(key)])\\n\\n        return values.collect()',\n",
       " 'language': 'python',\n",
       " 'func_code_string': 'def lookup(self, key):\\n        \"\"\"\\n        Return the list of values in the RDD for key `key`. This operation\\n        is done efficiently if the RDD has a known partitioner by only\\n        searching the partition that the key maps to.\\n\\n        >>> l = range(1000)\\n        >>> rdd = sc.parallelize(zip(l, l), 10)\\n        >>> rdd.lookup(42)  # slow\\n        [42]\\n        >>> sorted = rdd.sortByKey()\\n        >>> sorted.lookup(42)  # fast\\n        [42]\\n        >>> sorted.lookup(1024)\\n        []\\n        >>> rdd2 = sc.parallelize([((\\'a\\', \\'b\\'), \\'c\\')]).groupByKey()\\n        >>> list(rdd2.lookup((\\'a\\', \\'b\\'))[0])\\n        [\\'c\\']\\n        \"\"\"\\n        values = self.filter(lambda kv: kv[0] == key).values()\\n\\n        if self.partitioner is not None:\\n            return self.ctx.runJob(values, lambda x: x, [self.partitioner(key)])\\n\\n        return values.collect()',\n",
       " 'func_code_tokens': ['def',\n",
       "  'lookup',\n",
       "  '(',\n",
       "  'self',\n",
       "  ',',\n",
       "  'key',\n",
       "  ')',\n",
       "  ':',\n",
       "  'values',\n",
       "  '=',\n",
       "  'self',\n",
       "  '.',\n",
       "  'filter',\n",
       "  '(',\n",
       "  'lambda',\n",
       "  'kv',\n",
       "  ':',\n",
       "  'kv',\n",
       "  '[',\n",
       "  '0',\n",
       "  ']',\n",
       "  '==',\n",
       "  'key',\n",
       "  ')',\n",
       "  '.',\n",
       "  'values',\n",
       "  '(',\n",
       "  ')',\n",
       "  'if',\n",
       "  'self',\n",
       "  '.',\n",
       "  'partitioner',\n",
       "  'is',\n",
       "  'not',\n",
       "  'None',\n",
       "  ':',\n",
       "  'return',\n",
       "  'self',\n",
       "  '.',\n",
       "  'ctx',\n",
       "  '.',\n",
       "  'runJob',\n",
       "  '(',\n",
       "  'values',\n",
       "  ',',\n",
       "  'lambda',\n",
       "  'x',\n",
       "  ':',\n",
       "  'x',\n",
       "  ',',\n",
       "  '[',\n",
       "  'self',\n",
       "  '.',\n",
       "  'partitioner',\n",
       "  '(',\n",
       "  'key',\n",
       "  ')',\n",
       "  ']',\n",
       "  ')',\n",
       "  'return',\n",
       "  'values',\n",
       "  '.',\n",
       "  'collect',\n",
       "  '(',\n",
       "  ')'],\n",
       " 'func_documentation_string': \"Return the list of values in the RDD for key `key`. This operation\\n        is done efficiently if the RDD has a known partitioner by only\\n        searching the partition that the key maps to.\\n\\n        >>> l = range(1000)\\n        >>> rdd = sc.parallelize(zip(l, l), 10)\\n        >>> rdd.lookup(42)  # slow\\n        [42]\\n        >>> sorted = rdd.sortByKey()\\n        >>> sorted.lookup(42)  # fast\\n        [42]\\n        >>> sorted.lookup(1024)\\n        []\\n        >>> rdd2 = sc.parallelize([(('a', 'b'), 'c')]).groupByKey()\\n        >>> list(rdd2.lookup(('a', 'b'))[0])\\n        ['c']\",\n",
       " 'func_documentation_tokens': ['Return',\n",
       "  'the',\n",
       "  'list',\n",
       "  'of',\n",
       "  'values',\n",
       "  'in',\n",
       "  'the',\n",
       "  'RDD',\n",
       "  'for',\n",
       "  'key',\n",
       "  'key',\n",
       "  '.',\n",
       "  'This',\n",
       "  'operation',\n",
       "  'is',\n",
       "  'done',\n",
       "  'efficiently',\n",
       "  'if',\n",
       "  'the',\n",
       "  'RDD',\n",
       "  'has',\n",
       "  'a',\n",
       "  'known',\n",
       "  'partitioner',\n",
       "  'by',\n",
       "  'only',\n",
       "  'searching',\n",
       "  'the',\n",
       "  'partition',\n",
       "  'that',\n",
       "  'the',\n",
       "  'key',\n",
       "  'maps',\n",
       "  'to',\n",
       "  '.'],\n",
       " 'split_name': 'train',\n",
       " 'func_code_url': 'https://github.com/apache/spark/blob/618d6bff71073c8c93501ab7392c3cc579730f0b/python/pyspark/rdd.py#L2267-L2291'}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, -10:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class RNNCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        combined_size = self.input_size + self.hidden_size\n",
    "        self.i2h = nn.Linear(combined_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(inputs.device)   # (1,     H)\n",
    "        # inputs: (1, I)\n",
    "        combined = torch.cat((inputs, hidden), dim=1)  # (1, I + H)\n",
    "        hidden = F.relu(self.i2h(combined))            # (1,     H)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self, device):\n",
    "        return torch.zeros((1, self.hidden_size), device=device)\n",
    "\n",
    "\n",
    "r_model = RNNCell(2, 1)\n",
    "h = None\n",
    "hidden = []\n",
    "inputs = torch.randn(3, 1, 2)\n",
    "for i in range(3):\n",
    "    h = r_model(inputs[i], h)\n",
    "    hidden.append(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "f_outputs = torch.randn(10, 2, 3)\n",
    "b_outputs = torch.randn(10, 2, 3)\n",
    "\n",
    "l = [torch.cat((f, b), -1) for f, b in zip(\n",
    "        f_outputs, reversed(b_outputs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n",
      "torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "for f, b in zip(f_outputs, reversed(b_outputs)):\n",
    "    print(f.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 12])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnn = nn.RNN(3, 6, batch_first=True)\n",
    "b_rnn = nn.RNN(3, 6, batch_first=True)\n",
    "\n",
    "x = torch.randn(4, 10, 3)           # (B, T, C)\n",
    "f = f_rnn(x)[0]  # (B, T, H)\n",
    "b = b_rnn(reversed(x))[0]  # (B, T, H)\n",
    "o = torch.cat((f, reversed(b)), dim=-1)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rnn = nn.RNN(3, 5, batch_first=True)\n",
    "x = torch.randn(4, 10, 3)           # (B, T, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 10, 5]), torch.Size([4, 10, 5]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 12])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((f, b), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 6])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = nn.RNN(3, 6, batch_first=True)\n",
    "decoder = nn.RNN(3, 6, batch_first=True)\n",
    "h2o = nn.Linear(H, VS)\n",
    "\n",
    "x = torch.randn(4, 10, 3)   # (B, T, C)\n",
    "e = encoder(x)[0]           # (B, T, H)\n",
    "c = e[:, -1, :].unsqueeze(0)             # (B,    H)\n",
    "y = init\n",
    "while y != <|e|>:\n",
    "    c = decoder(y, c)\n",
    "    y = c.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        re = []\n",
    "        # B batch_size,\n",
    "        # T sequence length,\n",
    "        # C number of channels.\n",
    "        B, T, C = x.shape\n",
    "        x = x.transpose(0, 1) # (T, B, C)\n",
    "        seq_len = x.shape[0]\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(B, x.device)\n",
    "        for i in range(seq_len):\n",
    "            # x[i]: (B, C); hidden: (B, H)\n",
    "            combined = torch.cat((x[i], hidden), dim=1)\n",
    "            hidden = F.relu(self.i2h(combined))  # (   B, H)\n",
    "            re.append(hidden)\n",
    "        result_tensor = torch.stack(re, dim=0)   # (T, B, H)\n",
    "        return result_tensor.transpose(0, 1)     # (B, T, H)\n",
    "\n",
    "    def init_hidden(self, B, device):\n",
    "        return torch.zeros((B, self.hidden_size), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 4])\n",
      "torch.Size([5, 2, 4])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tttt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-d51dcf99c577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtttt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tttt' is not defined"
     ]
    }
   ],
   "source": [
    "encoder = RNN(4, 6)\n",
    "decoder = RNN(4, 6)\n",
    "h2i = nn.Linear(6, 4)\n",
    "\n",
    "\n",
    "x = torch.randn(5, 9, 4)                      # (B, T, C)\n",
    "e = encoder(x)          # (B, T, H)\n",
    "c = e[:, -1, :]         # (B,    H)\n",
    "y = torch.randn(5, 1, 4) # (B, 1, C)\n",
    "ix = ''\n",
    "while ix != '<|e|>':\n",
    "    h = decoder(y, c)[:, -1, :]   # (B, H)\n",
    "    #prob = F.softmax(h2o(h), dim=-1)  # (B, VS)\n",
    "    #ix = torch.multinomial(prob, num_samples=1)\n",
    "    ix = h2i(h).unsqueeze(1)\n",
    "    print(ix.shape)\n",
    "    y = torch.cat((y, ix), dim=1)\n",
    "    print(y.shape)\n",
    "    tttt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
