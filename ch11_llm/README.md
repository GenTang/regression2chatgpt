
|代码|说明|
|---|---|
|[char_gpt.ipynb](char_gpt.ipynb)| 从零开始实现GPT-2，并使用模型进行自然语言的自回归学习（根据背景文本预测下一个字母是什么） |
|[gpt2.ipynb](gpt2.ipynb)| 使用开源的GPT-2模型 |
|[lora_tutorial.ipynb](lora_tutorial.ipynb)| 实现简单版本的LoRA以及开源工具中LoRA的使用示例 |
|[gpt2_lora.ipynb](gpt2_lora.ipynb)| 使用LoRA对GPT-2进行监督微调（微调方式并不是最优的） |
|[gpt2\_lora_optimum.ipynb](gpt2_lora_optimum.ipynb)| 使用LoRA对GPT-2进行更优雅的监督微调 |
|[gpt2\_reward_modeling.ipynb](gpt2_reward_modeling.ipynb)| 使用LoRA对GPT-2进行评分建模 |