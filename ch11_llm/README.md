
|代码|说明|
|---|---|
|[char_gpt.ipynb](char_gpt.ipynb)| Creating GPT-2 from scratch and conducting autoregressive learning for python script (predict the next char based on context) |
|[gpt2.ipynb](gpt2.ipynb)| Usage of open-souce GPT-2 model |
|[lora_tutorial.ipynb](lora_tutorial.ipynb)| Implementation of LoRA (simple version) and usage of LoRA in peft |
|[gpt2_lora.ipynb](gpt2_lora.ipynb)| SFT (supervised fine-tuning) of GPT-2 by using LoRA (Note: This script is NOT  optimal) |
|[gpt2\_lora_optimum.ipynb](gpt2_lora_optimum.ipynb)| More elegant SFT on GPT-2 by using LoRA |
|[gpt2\_reward_modeling.ipynb](gpt2_reward_modeling.ipynb)| Reward modeling on GPT-2 by using LoRA |